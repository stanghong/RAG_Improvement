{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# Evaluation with RAGAS and Advanced Retrieval Methods Using LangChain\n",
        "\n",
        "In the following notebook we'll discuss a major component of LLM Ops:\n",
        "\n",
        "- Evaluation\n",
        "\n",
        "We're going to be leveraging the [RAGAS]() framework for our evaluations today as it's becoming a standard method of evaluating (at least directionally) RAG systems.\n",
        "\n",
        "We're also going to discuss a few more powerful Retrieval Systems that can potentially improve the quality of our generations!\n",
        "\n",
        "Let's start as we always do: Grabbing our dependencies!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BN13TZlSCv4",
        "outputId": "e0adb916-54e7-4eb7-fec5-86fe312bcda9"
      },
      "outputs": [],
      "source": [
        "# !pip install -U -q langchain openai ragas arxiv pymupdf chromadb wandb tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 1: Load dataset and Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_utils import word_wrap\n",
        "from pypdf import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
        "import os\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "# import umap.umap_ as umap\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import CrossEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "fc978089-8bdb-4fa2-907e-f006a69388d7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "_ = load_dotenv('.env')\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV_BOewX8CW0"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We're going to be using papers from Arxiv as our context today.\n",
        "\n",
        "We can collect these documents rather straightforwardly with the `ArxivLoader` document loader from LangChain.\n",
        "\n",
        "Let's grab and load 5 documents.\n",
        "\n",
        "- [`ArxivLoader`](https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.arxiv.ArxivLoader.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "such\trisks\thave\toccurred\tat\tthe\ttime\tof\tthis\tfiling.\tWe\tdo\tnot\tassume\tany\tobligation\tto\tupdate\tany\tforward-looking\tstatements.\n",
            "\n",
            "Total chunks: 528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hongtang/Documents/RAG_Brewer/notebooks/RAG_POC/rag_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='such risks have occurred at the time of this filing. we do not assume any obligation to update any forward - looking statements.' metadata={'page_number': 4}\n",
            "\n",
            "Total documents: 556\n",
            "Vectorstore created successfully.\n"
          ]
        }
      ],
      "source": [
        "# from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
        "from langchain.schema import Document\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load Tesla 2023 10K report\n",
        "reader = PdfReader(\"./data/tesla10K.pdf\")\n",
        "\n",
        "# Extract text from each page and store with page numbers\n",
        "pdf_texts = []\n",
        "for page_num, page in enumerate(reader.pages):\n",
        "    text = page.extract_text().strip()\n",
        "    if text:\n",
        "        pdf_texts.append({\"page_number\": page_num + 1, \"content\": text})\n",
        "\n",
        "# Split text by sentences while maintaining page number\n",
        "character_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=0\n",
        ")\n",
        "\n",
        "# Split each page's content and store in a list with metadata\n",
        "character_split_texts = []\n",
        "for entry in pdf_texts:\n",
        "    chunks = character_splitter.split_text(entry[\"content\"])\n",
        "    for chunk in chunks:\n",
        "        character_split_texts.append({\"page_number\": entry[\"page_number\"], \"content\": chunk})\n",
        "\n",
        "# Print an example chunk and total number of chunks\n",
        "print(character_split_texts[10][\"content\"])\n",
        "print(f\"\\nTotal chunks: {len(character_split_texts)}\")\n",
        "\n",
        "# Tokenize the sentence chunks\n",
        "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
        "\n",
        "# Split each character chunk while maintaining metadata\n",
        "token_split_texts = []\n",
        "for entry in character_split_texts:\n",
        "    chunks = token_splitter.split_text(entry[\"content\"])\n",
        "    for chunk in chunks:\n",
        "        token_split_texts.append({\"page_number\": entry[\"page_number\"], \"content\": chunk})\n",
        "\n",
        "# Create base_docs structure\n",
        "base_docs = []\n",
        "for entry in token_split_texts:\n",
        "    base_docs.append(Document(page_content=entry[\"content\"], metadata={\"page_number\": entry[\"page_number\"]}))\n",
        "\n",
        "# Print an example document from base_docs and total number of documents\n",
        "print(base_docs[10])\n",
        "print(f\"\\nTotal documents: {len(base_docs)}\")\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "\n",
        "# Define the embedding function using SentenceTransformer\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Use the embedding function with Chroma\n",
        "vectorstore = Chroma.from_documents(base_docs, embedding_function)\n",
        "\n",
        "print(\"Vectorstore created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Function to print documents with wrapped text\n",
        "def print_documents_with_wrap(documents, width=70):\n",
        "    for doc in documents:\n",
        "        wrapped_content = textwrap.fill(doc.page_content, width=width)\n",
        "        print(f\"Page Number: {doc.metadata['page_number']}\\n\")\n",
        "        print(wrapped_content)\n",
        "        print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
        "\n",
        "# Example usage\n",
        "# print_documents_with_wrap(base_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hongtang/Documents/RAG_Brewer/notebooks/RAG_POC/rag_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "relevant_docs = base_retriever.get_relevant_documents(\"What is tesla 2023 revenue?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "### Creating an Index\n",
        "\n",
        "Let's use a naive index creation strategy of just using `RecursiveCharacterTextSplitter` on our documents and embedding each into our `VectorStore` using `OpenAIEmbeddings()`.\n",
        "\n",
        "- [`RecursiveCharacterTextSplitter()`](https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html)\n",
        "- [`Chroma`](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html?highlight=chroma#langchain.vectorstores.chroma.Chroma)\n",
        "- [`OpenAIEmbeddings()`](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html?highlight=openaiembeddings#langchain-embeddings-openai-openaiembeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# # Create Document objects from base_docs\n",
        "# documents = [Document(page_content=doc[\"content\"], metadata=doc[\"metadata\"]) for doc in base_docs]\n",
        "\n",
        "# # Initialize the text splitter\n",
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=250)\n",
        "\n",
        "# # Split the documents\n",
        "# docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# # Initialize the vector store with the documents and embeddings\n",
        "# vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())\n",
        "\n",
        "# print(\"Vector store created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xne8P5dQTUiR",
        "outputId": "3b0a58ee-791c-4ddf-ed0d-11a3a0b8278f"
      },
      "outputs": [],
      "source": [
        "# from langchain.vectorstores import Chroma\n",
        "# from langchain.embeddings import OpenAIEmbeddings\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=250)\n",
        "\n",
        "# docs = text_splitter.split_documents(base_docs)\n",
        "\n",
        "# vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MKsT6JTgCU"
      },
      "source": [
        "## Creating a Retrieval Augmented Generation Prompt\n",
        "\n",
        "Now we can set up a prompt template that will be used to provide the LLM with the necessary contexts, user query, and instructions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ijSNkTAjTsep"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "### CONTEXT\n",
        "{context}\n",
        "\n",
        "### QUESTION\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHnPaXl-cvJ"
      },
      "source": [
        "### Setting Up our Basic QA Chain\n",
        "\n",
        "Now we can instantiate our basic RAG chain!\n",
        "\n",
        "We'll follow *exactly* the chain we made on Tuesday to keep things simple for now - if you need a refresher on what it looked like - check out last week's notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TsjUWjbUfbW",
        "outputId": "0b5095b1-108b-43e9-a464-00a208c4ff46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hongtang/Documents/RAG_Brewer/notebooks/RAG_POC/rag_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | base_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO69de-F-oMD"
      },
      "source": [
        "Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS5NxC6UyU2",
        "outputId": "93526abe-b29f-4662-9b5b-c88dfbf35565"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'response': AIMessage(content=\"Answer: Tesla's 2023 revenue is $96,773 million. This is calculated by adding up the total automotive revenues ($82,419 million), energy generation and storage revenues ($6,035 million), and services and other revenues ($8,319 million).\", response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 586, 'total_tokens': 639}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-499c253c-8d91-413c-94b7-72fc1ca2fb5e-0'), 'context': [Document(page_content='tesla, inc. consolidated statements of operations ( in millions, except per share data ) year ended december 31, 2023 2022 2021 revenues automotive sales $ 78, 509 $ 67, 210 $ 44, 125 automotive regulatory credits 1, 790 1, 776 1, 465 automotive leasing 2, 120 2, 476 1, 642 total automotive revenues 82, 419 71, 462 47, 232 energy generation and storage 6, 035 3, 909 2, 789 services and other 8, 319 6, 091 3, 802 total revenues 96, 773 81, 462 53, 823 cost of revenues automotive sales 65, 121 49, 599 32, 415 automotive leasing 1, 268 1, 509 978 total automotive cost of revenues 66, 389 51, 108 33, 393 energy generation and storage 4, 894 3, 621 2, 918 services and other 7, 830 5, 880 3, 906 total cost of revenues 79, 113 60, 609 40, 217 gross profit 17, 660 20, 853 13, 606 operating expenses research and development 3, 969 3, 075 2, 593 selling, general and administrative 4, 800 3, 946 4', metadata={'page_number': 51}), Document(page_content='energy storage manufacture or purchase, including through providing tax credits to consumers. for example, qualifying tesla customers may receive up to $ 7, 500 in federal tax credits for the purchase of qualified electric vehicles in the u. s. through 2032. automotive regulatory credits we earn tradable credits in the operation of our business under various regulations related to zero - emission vehicles ( “ zevs ” ), greenhouse gas, fuel economy and clean fuel. we sell these credits to other regulated entities who can use the credits to comply with emission standards and other regulatory requirements. sales of these credits are recognized within automotive regulatory credits revenue in our consolidated statements of operations included elsewhere in this annual report on form 10 - k. energy storage system incentives and policies while the regulatory regime for energy storage projects is still under development, there are various policies, incentives and financial mechanisms', metadata={'page_number': 10})]}\n"
          ]
        }
      ],
      "source": [
        "question = \"What is tesla 2023 revenue and show how do you get it\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import textwrap\n",
        "from langchain.schema import Document\n",
        "from langchain.schema.messages import AIMessage  # Import AIMessage or other message types as needed\n",
        "\n",
        "def convert_to_serializable(obj):\n",
        "    if isinstance(obj, Document):\n",
        "        return {\"page_content\": obj.page_content, \"metadata\": obj.metadata}\n",
        "    if isinstance(obj, AIMessage):\n",
        "        return {\"content\": obj.content}  # Adjust based on actual structure of AIMessage\n",
        "    raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n",
        "\n",
        "def pretty_print_dict_wrapped(d, width=70):\n",
        "    \"\"\"\n",
        "    Prints a dictionary in a formatted and more readable way with wrapped text.\n",
        "    \n",
        "    Args:\n",
        "    d (dict): The dictionary to print.\n",
        "    width (int): The maximum width of the wrapped text.\n",
        "    \"\"\"\n",
        "    print(textwrap.fill(json.dumps(d, indent=4, sort_keys=True, default=convert_to_serializable), width=width))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pretty_print_dict_wrapped(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code to generate ground truth\n",
        "* question\n",
        "* answer\n",
        "* context\n",
        "* ground truth [GPT4 answered based on the context and question]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs=base_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "question\n",
            "What is the trading symbol for Tesla's common stock on the Nasdaq Global Select Market?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:13<00:00,  1.39s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "answer\n",
            "TSLA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:23<00:00,  2.35s/it]\n",
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 197.40ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "11604"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "#genreeate questions based on the doc contents\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "question_schema = ResponseSchema(\n",
        "    name=\"question\",\n",
        "    description=\"a question about the context.\"\n",
        ")\n",
        "\n",
        "question_response_schemas = [\n",
        "    question_schema,\n",
        "]\n",
        "question_output_parser = StructuredOutputParser.from_response_schemas(question_response_schemas)\n",
        "format_instructions = question_output_parser.get_format_instructions()\n",
        "question_generation_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
        "\n",
        "bare_prompt_template = \"{content}\"\n",
        "bare_template = ChatPromptTemplate.from_template(template=bare_prompt_template)\n",
        "\n",
        "\n",
        "qa_template = \"\"\"\\\n",
        "You are a University Professor creating a test for advanced students. For each context, create a question that is specific to the context. Avoid creating generic or general questions.\n",
        "\n",
        "question: a question about the context.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "question\n",
        "\n",
        "context: {context}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    context=docs[0],\n",
        "    format_instructions=format_instructions\n",
        ")\n",
        "\n",
        "question_generation_chain = bare_template | question_generation_llm\n",
        "\n",
        "response = question_generation_chain.invoke({\"content\" : messages})\n",
        "output_dict = question_output_parser.parse(response.content)\n",
        "for k, v in output_dict.items():\n",
        "  print(k)\n",
        "  print(v)\n",
        "\n",
        "\n",
        "#create qac_triples\n",
        "qac_triples = []\n",
        "\n",
        "for text in tqdm(docs[:10]):\n",
        "  messages = prompt_template.format_messages(\n",
        "      context=text,\n",
        "      format_instructions=format_instructions\n",
        "  )\n",
        "  response = question_generation_chain.invoke({\"content\" : messages}) # genrate questions\n",
        "  try:\n",
        "    output_dict = question_output_parser.parse(response.content) #question and answer\n",
        "  except Exception as e:\n",
        "    continue\n",
        "  output_dict[\"context\"] = text\n",
        "  qac_triples.append(output_dict)\n",
        "\n",
        "#add answer to qac_triples\n",
        "answer_generation_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "answer_schema = ResponseSchema(\n",
        "    name=\"answer\",\n",
        "    description=\"an answer to the question\"\n",
        ")\n",
        "\n",
        "answer_response_schemas = [\n",
        "    answer_schema,\n",
        "]\n",
        "\n",
        "answer_output_parser = StructuredOutputParser.from_response_schemas(answer_response_schemas)\n",
        "format_instructions = answer_output_parser.get_format_instructions()\n",
        "\n",
        "qa_template = \"\"\"\\\n",
        "You are a University Professor creating a test for advanced students. For each question and context, create an answer.\n",
        "\n",
        "answer: a answer about the context.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "answer\n",
        "\n",
        "question: {question}\n",
        "context: {context}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    context=qac_triples[0][\"context\"],\n",
        "    question=qac_triples[0][\"question\"],\n",
        "    format_instructions=format_instructions\n",
        ")\n",
        "\n",
        "answer_generation_chain = bare_template | answer_generation_llm\n",
        "\n",
        "response = answer_generation_chain.invoke({\"content\" : messages})\n",
        "output_dict = answer_output_parser.parse(response.content)\n",
        "for k, v in output_dict.items():\n",
        "  print(k)\n",
        "  print(v)\n",
        "for triple in tqdm(qac_triples):\n",
        "  messages = prompt_template.format_messages(\n",
        "      context=triple[\"context\"],\n",
        "      question=triple[\"question\"],\n",
        "      format_instructions=format_instructions\n",
        "  )\n",
        "  response = answer_generation_chain.invoke({\"content\" : messages})\n",
        "  try:\n",
        "    output_dict = answer_output_parser.parse(response.content)\n",
        "  except Exception as e:\n",
        "    continue\n",
        "  triple[\"answer\"] = output_dict[\"answer\"]\n",
        "#ground truth dataset\n",
        "\n",
        "ground_truth_qac_set = pd.DataFrame(qac_triples)\n",
        "ground_truth_qac_set[\"context\"] = ground_truth_qac_set[\"context\"].map(lambda x: str(x.page_content))\n",
        "ground_truth_qac_set = ground_truth_qac_set.rename(columns={\"answer\" : \"ground_truth\"})\n",
        "\n",
        "\n",
        "eval_dataset = Dataset.from_pandas(ground_truth_qac_set)\n",
        "eval_dataset.to_csv(\"groundtruth_eval_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the trading symbol for Tesla's common ...</td>\n",
              "      <td>united states securities and exchange commissi...</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>According to the context, has the registrant f...</td>\n",
              "      <td>securities registered pursuant to section 12 (...</td>\n",
              "      <td>Yes, the registrant has filed all reports requ...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>According to the given context, what is the re...</td>\n",
              "      <td>( § 232. 405 of this chapter ) during the prec...</td>\n",
              "      <td>large accelerated filer</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Has the registrant elected to use the extended...</td>\n",
              "      <td>if an emerging growth company, indicate by che...</td>\n",
              "      <td>The context does not provide a direct answer t...</td>\n",
              "      <td>{'page_number': 2}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the given context, what is the ag...</td>\n",
              "      <td>indicate by check mark whether any of those er...</td>\n",
              "      <td>The aggregate market value of voting stock hel...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is the number of shares of the registrant...</td>\n",
              "      <td>as of january 22, 2024, there were 3, 184, 790...</td>\n",
              "      <td>As of January 22, 2024, there were 3,184,790,4...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the purpose of the annual report on Fo...</td>\n",
              "      <td>tesla, inc. annual report on form 10 - k for t...</td>\n",
              "      <td>The purpose of the annual report on Form 10-K ...</td>\n",
              "      <td>{'page_number': 3}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What information is included in item 14 of the...</td>\n",
              "      <td>item 11. executive compensation 95 item 12. se...</td>\n",
              "      <td>Item 14 of the document includes information a...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What are some of the topics covered in the for...</td>\n",
              "      <td>table of contents forward - looking statements...</td>\n",
              "      <td>The forward-looking statements in this annual ...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What risks are disclosed in the annual report ...</td>\n",
              "      <td>statements contain these identifying words. we...</td>\n",
              "      <td>The risks disclosed in the annual report on Fo...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What is the trading symbol for Tesla's common ...   \n",
              "1  According to the context, has the registrant f...   \n",
              "2  According to the given context, what is the re...   \n",
              "3  Has the registrant elected to use the extended...   \n",
              "4  According to the given context, what is the ag...   \n",
              "5  What is the number of shares of the registrant...   \n",
              "6  What is the purpose of the annual report on Fo...   \n",
              "7  What information is included in item 14 of the...   \n",
              "8  What are some of the topics covered in the for...   \n",
              "9  What risks are disclosed in the annual report ...   \n",
              "\n",
              "                                             context  \\\n",
              "0  united states securities and exchange commissi...   \n",
              "1  securities registered pursuant to section 12 (...   \n",
              "2  ( § 232. 405 of this chapter ) during the prec...   \n",
              "3  if an emerging growth company, indicate by che...   \n",
              "4  indicate by check mark whether any of those er...   \n",
              "5  as of january 22, 2024, there were 3, 184, 790...   \n",
              "6  tesla, inc. annual report on form 10 - k for t...   \n",
              "7  item 11. executive compensation 95 item 12. se...   \n",
              "8  table of contents forward - looking statements...   \n",
              "9  statements contain these identifying words. we...   \n",
              "\n",
              "                                        ground_truth            metadata  \n",
              "0                                               TSLA                None  \n",
              "1  Yes, the registrant has filed all reports requ...                None  \n",
              "2                            large accelerated filer                None  \n",
              "3  The context does not provide a direct answer t...  {'page_number': 2}  \n",
              "4  The aggregate market value of voting stock hel...                None  \n",
              "5  As of January 22, 2024, there were 3,184,790,4...                None  \n",
              "6  The purpose of the annual report on Form 10-K ...  {'page_number': 3}  \n",
              "7  Item 14 of the document includes information a...                None  \n",
              "8  The forward-looking statements in this annual ...                None  \n",
              "9  The risks disclosed in the annual report on Fo...                None  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test chunk size sensitivity using RAGAS metrics\n",
        "# test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create pipeline testing chunksize sensitivity\n",
        "# use openai embedding, need to test on chromadb embedding cheaper option\n",
        "\n",
        "# from langchain.vectorstores import Chroma\n",
        "# from langchain.embeddings import OpenAIEmbeddings\n",
        "# from langchain.schema import Document\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# def qa_sensitivity(base_docs, chunk_size, question):\n",
        "#     # Create Document objects from base_docs\n",
        "#     documents = [Document(page_content=doc[\"content\"], metadata=doc[\"metadata\"]) for doc in base_docs]\n",
        "\n",
        "#     # Initialize the text splitter\n",
        "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size)\n",
        "\n",
        "#     # Split the documents\n",
        "#     docs = text_splitter.split_documents(documents)\n",
        "\n",
        "#     # Initialize the vector store with the documents and embeddings\n",
        "#     vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())\n",
        "\n",
        "#     # print(\"Vector store created successfully.\")\n",
        "\n",
        "#     result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "#     return result\n",
        "\n",
        "# question = \"What is tesla 2023 revenue\"\n",
        "# chunk_size=200\n",
        "# result= qa_sensitivity(base_docs, chunk_size, question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extracting the response content\n",
        "# response_content = result['response'].content\n",
        "\n",
        "# # Extracting the context content\n",
        "# context_content = [doc.page_content for doc in result['context']]\n",
        "\n",
        "# print(\"Response Content:\", response_content)\n",
        "# print(\"Context Content:\", context_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#chromaDB option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# reader = PdfReader(\"./data/tesla10K.pdf\")\n",
        "# pdf_texts = [p.extract_text().strip() for p in reader.pages if p.extract_text()]\n",
        "\n",
        "# # Split text by sentences\n",
        "# character_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"], chunk_size=1000, chunk_overlap=0)\n",
        "# character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create pipeline testing chunksize sensitivity\n",
        "# use openai embedding, need to test on chromadb embedding cheaper option\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "# from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hongtang/Documents/RAG_Brewer/notebooks/RAG_POC/rag_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'tesla202310k_256' created and documents added successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 10 examples [00:00, 1483.92 examples/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.16it/s]\n",
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating:   7%|▋         | 5/70 [00:01<00:17,  3.68it/s]No statements were generated from the answer.\n",
            "Evaluating:  19%|█▊        | 13/70 [00:03<00:10,  5.54it/s]No statements were generated from the answer.\n",
            "Evaluating:  49%|████▊     | 34/70 [00:06<00:06,  5.45it/s]No statements were generated from the answer.\n",
            "Evaluating:  81%|████████▏ | 57/70 [00:23<00:15,  1.23s/it]No statements were generated from the answer.\n",
            "Evaluating: 100%|██████████| 70/70 [00:57<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 0.9000, 'faithfulness': 0.7500, 'answer_relevancy': 0.4812, 'context_recall': 0.8000, 'context_relevancy': 0.1320, 'answer_correctness': 0.4701, 'answer_similarity': 0.8304}\n"
          ]
        }
      ],
      "source": [
        "class RAGPipeline:\n",
        "    def __init__(self, character_split_texts, tokens_per_chunk):\n",
        "        self.tokens_per_chunk = tokens_per_chunk\n",
        "        self.character_split_texts = character_split_texts\n",
        "        self.embedding_function = SentenceTransformerEmbeddingFunction()\n",
        "        self.token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=tokens_per_chunk)\n",
        "\n",
        "        # Tokenize the sentence chunks\n",
        "        self.token_split_texts = [token_split_text for text in character_split_texts for token_split_text in self.token_splitter.split_text(text)]\n",
        "\n",
        "        # Create vector database using ChromaDB collection\n",
        "        self.chroma_client = chromadb.Client()\n",
        "        collection_name = f\"tesla202310k_{tokens_per_chunk}\"\n",
        "\n",
        "        # Check if the collection exists\n",
        "        if self.collection_exists(collection_name):\n",
        "            self.chroma_collection = self.chroma_client.get_collection(collection_name)\n",
        "            print(f\"Collection '{collection_name}' already exists. Using existing collection.\")\n",
        "        else:\n",
        "            self.chroma_collection = self.chroma_client.create_collection(collection_name, embedding_function=self.embedding_function)\n",
        "            ids = [str(i) for i in range(len(self.token_split_texts))]\n",
        "            self.chroma_collection.add(ids=ids, documents=self.token_split_texts)\n",
        "            print(f\"Collection '{collection_name}' created and documents added successfully.\")\n",
        "\n",
        "    def collection_exists(self, collection_name):\n",
        "        try:\n",
        "            self.chroma_client.get_collection(collection_name)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            return False\n",
        "\n",
        "    def invoke(self, input_dict):\n",
        "        question = input_dict.get(\"question\")\n",
        "        result = retrieval_augmented_qa_chain.invoke({\"question\": question})\n",
        "        return result\n",
        "\n",
        "# Function to use the RAGPipeline\n",
        "def qa_sensitivity(character_split_texts, tokens_per_chunk, question):\n",
        "    rag_pipeline = RAGPipeline(character_split_texts, tokens_per_chunk)\n",
        "    result = rag_pipeline.invoke({\"question\": question})\n",
        "    return result\n",
        "\n",
        "# Define the parameters\n",
        "tokens_per_chunk = 256\n",
        "# character_split_texts = [\"Your character split texts go here\"]\n",
        "\n",
        "# Create an instance of RAGPipeline\n",
        "rag_pipeline = RAGPipeline(character_split_texts, tokens_per_chunk)\n",
        "\n",
        "# Invoke the method\n",
        "# result = rag_pipeline.invoke({\"question\": \"What is the revenue for Tesla in 2023?\"})\n",
        "# print(result)\n",
        "\n",
        "# see below on how to create eval_dataset\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    context_relevancy,\n",
        "    answer_correctness,\n",
        "    answer_similarity\n",
        ")\n",
        "\n",
        "from ragas.metrics.critique import harmfulness\n",
        "from ragas import evaluate\n",
        "\n",
        "def create_ragas_dataset(rag_pipeline, eval_dataset):\n",
        "    rag_dataset = []\n",
        "    for row in tqdm(eval_dataset):\n",
        "        answer = rag_pipeline.invoke({\"question\" : row[\"question\"]})\n",
        "        rag_dataset.append(\n",
        "            {\"question\" : row[\"question\"],\n",
        "             \"answer\" : answer[\"response\"].content,\n",
        "             \"contexts\" : [context.page_content for context in answer[\"context\"]],\n",
        "             \"ground_truths\" : [row[\"ground_truth\"]]\n",
        "             }\n",
        "        )\n",
        "    rag_df = pd.DataFrame(rag_dataset)\n",
        "    rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
        "    return rag_eval_dataset\n",
        "\n",
        "def evaluate_ragas_dataset(ragas_dataset):\n",
        "    result = evaluate(\n",
        "        ragas_dataset,\n",
        "        metrics=[\n",
        "            context_precision,\n",
        "            faithfulness,\n",
        "            answer_relevancy,\n",
        "            context_recall,\n",
        "            context_relevancy,\n",
        "            answer_correctness,\n",
        "            answer_similarity\n",
        "        ],\n",
        "    )\n",
        "    return result\n",
        "\n",
        "# Load the evaluation dataset\n",
        "eval_dataset = Dataset.from_csv(\"groundtruth_eval_dataset.csv\")\n",
        "\n",
        "# Create the RAGAS dataset\n",
        "ragas_dataset = create_ragas_dataset(rag_pipeline, eval_dataset)\n",
        "\n",
        "# Evaluate the RAGAS dataset\n",
        "evaluation_results = evaluate_ragas_dataset(ragas_dataset)\n",
        "print(evaluation_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the trading symbol for Tesla's common ...</td>\n",
              "      <td>Answer: TSLA</td>\n",
              "      <td>[united states securities and exchange commiss...</td>\n",
              "      <td>[TSLA]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Has the registrant filed all reports required ...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>[securities registered pursuant to section 12 ...</td>\n",
              "      <td>[Yes, the registrant has filed all reports req...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>According to the provided information, is the ...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>[( § 232. 405 of this chapter ) during the pre...</td>\n",
              "      <td>[Yes, the registrant is a large accelerated fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to the given context, has the regist...</td>\n",
              "      <td>Yes, the registrant has elected not to use the...</td>\n",
              "      <td>[if an emerging growth company, indicate by ch...</td>\n",
              "      <td>[No, the registrant has not elected to use the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the context, what is the aggregat...</td>\n",
              "      <td>Answer: $722.52 billion</td>\n",
              "      <td>[indicate by check mark whether any of those e...</td>\n",
              "      <td>[The aggregate market value of voting stock he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How many shares of the registrant's common sto...</td>\n",
              "      <td>Answer: 3,184,790,415 shares</td>\n",
              "      <td>[as of january 22, 2024, there were 3, 184, 79...</td>\n",
              "      <td>[As of January 22, 2024, there were 3,184,790,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the purpose of the annual report on Fo...</td>\n",
              "      <td>Answer: The purpose of the annual report on Fo...</td>\n",
              "      <td>[weisshorn solar manager i, llc delaware zep s...</td>\n",
              "      <td>[The purpose of the annual report on Form 10-K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What information is included in item 13 of the...</td>\n",
              "      <td>I don't know</td>\n",
              "      <td>[item 13. certain relationships and related tr...</td>\n",
              "      <td>[Item 13 of the document includes information ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What specific statements are included in the f...</td>\n",
              "      <td>The specific statements included in the forwar...</td>\n",
              "      <td>[statements contain these identifying words. w...</td>\n",
              "      <td>[The forward-looking statements in this annual...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What are the risks and uncertainties mentioned...</td>\n",
              "      <td>The risks and uncertainties mentioned in the f...</td>\n",
              "      <td>[statements contain these identifying words. w...</td>\n",
              "      <td>[The risks and uncertainties mentioned in the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What is the trading symbol for Tesla's common ...   \n",
              "1  Has the registrant filed all reports required ...   \n",
              "2  According to the provided information, is the ...   \n",
              "3  According to the given context, has the regist...   \n",
              "4  According to the context, what is the aggregat...   \n",
              "5  How many shares of the registrant's common sto...   \n",
              "6  What is the purpose of the annual report on Fo...   \n",
              "7  What information is included in item 13 of the...   \n",
              "8  What specific statements are included in the f...   \n",
              "9  What are the risks and uncertainties mentioned...   \n",
              "\n",
              "                                              answer  \\\n",
              "0                                       Answer: TSLA   \n",
              "1                                               Yes.   \n",
              "2                                               Yes.   \n",
              "3  Yes, the registrant has elected not to use the...   \n",
              "4                            Answer: $722.52 billion   \n",
              "5                       Answer: 3,184,790,415 shares   \n",
              "6  Answer: The purpose of the annual report on Fo...   \n",
              "7                                       I don't know   \n",
              "8  The specific statements included in the forwar...   \n",
              "9  The risks and uncertainties mentioned in the f...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [united states securities and exchange commiss...   \n",
              "1  [securities registered pursuant to section 12 ...   \n",
              "2  [( § 232. 405 of this chapter ) during the pre...   \n",
              "3  [if an emerging growth company, indicate by ch...   \n",
              "4  [indicate by check mark whether any of those e...   \n",
              "5  [as of january 22, 2024, there were 3, 184, 79...   \n",
              "6  [weisshorn solar manager i, llc delaware zep s...   \n",
              "7  [item 13. certain relationships and related tr...   \n",
              "8  [statements contain these identifying words. w...   \n",
              "9  [statements contain these identifying words. w...   \n",
              "\n",
              "                                       ground_truths  \n",
              "0                                             [TSLA]  \n",
              "1  [Yes, the registrant has filed all reports req...  \n",
              "2  [Yes, the registrant is a large accelerated fi...  \n",
              "3  [No, the registrant has not elected to use the...  \n",
              "4  [The aggregate market value of voting stock he...  \n",
              "5  [As of January 22, 2024, there were 3,184,790,...  \n",
              "6  [The purpose of the annual report on Form 10-K...  \n",
              "7  [Item 13 of the document includes information ...  \n",
              "8  [The forward-looking statements in this annual...  \n",
              "9  [The risks and uncertainties mentioned in the ...  "
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test the chunk size to be half of previous one\n",
        "pd.DataFrame(ragas_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'tesla202310k_128' created and documents added successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:07<00:00,  1.40it/s]\n",
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating:  54%|█████▍    | 38/70 [00:04<00:02, 13.68it/s]No statements were generated from the answer.\n",
            "Evaluating:  60%|██████    | 42/70 [00:05<00:03,  8.59it/s]No statements were generated from the answer.\n",
            "Evaluating: 100%|██████████| 70/70 [00:29<00:00,  2.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 1.0000, 'faithfulness': 1.0000, 'answer_relevancy': 0.7583, 'context_recall': 1.0000, 'context_relevancy': 0.1363, 'answer_correctness': 0.7014, 'answer_similarity': 0.8655}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the parameters\n",
        "tokens_per_chunk = 128\n",
        "# character_split_texts = [\"Your character split texts go here\"]\n",
        "\n",
        "# Create an instance of RAGPipeline\n",
        "rag_pipeline = RAGPipeline(character_split_texts, tokens_per_chunk)\n",
        "\n",
        "# Create the RAGAS dataset\n",
        "ragas_dataset = create_ragas_dataset(rag_pipeline, eval_dataset)\n",
        "\n",
        "# Evaluate the RAGAS dataset\n",
        "evaluation_results = evaluate_ragas_dataset(ragas_dataset)\n",
        "print(evaluation_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'tesla202310k_64' created and documents added successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.23it/s]\n",
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating:  73%|███████▎  | 51/70 [00:07<00:02,  8.74it/s]No statements were generated from the answer.\n",
            "Evaluating: 100%|██████████| 70/70 [00:30<00:00,  2.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 1.0000, 'faithfulness': 1.0000, 'answer_relevancy': 0.8574, 'context_recall': 1.0000, 'context_relevancy': 0.1363, 'answer_correctness': 0.7742, 'answer_similarity': 0.8794}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the parameters\n",
        "tokens_per_chunk = 64\n",
        "# character_split_texts = [\"Your character split texts go here\"]\n",
        "\n",
        "# Create an instance of RAGPipeline\n",
        "rag_pipeline = RAGPipeline(character_split_texts, tokens_per_chunk)\n",
        "\n",
        "# Create the RAGAS dataset\n",
        "ragas_dataset = create_ragas_dataset(rag_pipeline, eval_dataset)\n",
        "\n",
        "# Evaluate the RAGAS dataset\n",
        "evaluation_results = evaluate_ragas_dataset(ragas_dataset)\n",
        "print(evaluation_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ValueError: The token limit of the models 'sentence-transformers/all-mpnet-base-v2' is: 384. Argument tokens_per_chunk=512 > maximum token limit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'tesla202310k_384' created and documents added successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:07<00:00,  1.35it/s]\n",
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating:  56%|█████▌    | 39/70 [00:06<00:03, 10.13it/s]No statements were generated from the answer.\n",
            "Evaluating: 100%|██████████| 70/70 [00:29<00:00,  2.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 1.0000, 'faithfulness': 1.0000, 'answer_relevancy': 0.8573, 'context_recall': 1.0000, 'context_relevancy': 0.1363, 'answer_correctness': 0.7742, 'answer_similarity': 0.8794}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the parameters\n",
        "tokens_per_chunk = 384\n",
        "# character_split_texts = [\"Your character split texts go here\"]\n",
        "\n",
        "# Create an instance of RAGPipeline\n",
        "rag_pipeline = RAGPipeline(character_split_texts, tokens_per_chunk)\n",
        "\n",
        "# Create the RAGAS dataset\n",
        "ragas_dataset = create_ragas_dataset(rag_pipeline, eval_dataset)\n",
        "\n",
        "# Evaluate the RAGAS dataset\n",
        "evaluation_results = evaluate_ragas_dataset(ragas_dataset)\n",
        "print(evaluation_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>context_precision</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>faithfulness</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_relevancy</th>\n",
              "      <td>0.857432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context_recall</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context_relevancy</th>\n",
              "      <td>0.136346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_correctness</th>\n",
              "      <td>0.774174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_similarity</th>\n",
              "      <td>0.879449</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           0\n",
              "context_precision   1.000000\n",
              "faithfulness        1.000000\n",
              "answer_relevancy    0.857432\n",
              "context_recall      1.000000\n",
              "context_relevancy   0.136346\n",
              "answer_correctness  0.774174\n",
              "answer_similarity   0.879449"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame.from_dict(evaluation_results, orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ndcg(scores, ideal_scores, k):\n",
        "    dcg = lambda scores: sum((2**score - 1) / np.log2(idx + 2) for idx, score in enumerate(scores[:k]))\n",
        "    actual_dcg = dcg(scores)\n",
        "    ideal_dcg = dcg(sorted(ideal_scores, reverse=True))\n",
        "    return actual_dcg / ideal_dcg if ideal_dcg > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# relevancy rank method 1\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "def rank_relevancy_pairs(pairs, k_pairs):\n",
        "    # Initialize the CrossEncoder with a specific pre-trained model\n",
        "    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "    \n",
        "    # Predict scores for the pairs using the CrossEncoder\n",
        "    scores = cross_encoder.predict(pairs)\n",
        "    \n",
        "    # Select top 5 ranked answers by sorting the indices of scores in descending order\n",
        "    top_indices = np.argsort(scores)[::-1][:k_pairs]  # Select only the top 5\n",
        "    \n",
        "    # Assign relevancy scores from 4 to 0 (or less based on list length)\n",
        "    predicted_relevance = [0] * k_pairs\n",
        "    for rank, index in enumerate(top_indices):\n",
        "        predicted_relevance[index] = k_pairs-1 - rank  # Adjust this based on how many scores there are\n",
        "    \n",
        "    # Retrieve the top 5 pairs based on these indices\n",
        "    top_pairs = [pairs[index] for index in top_indices]\n",
        "    \n",
        "    return top_indices, predicted_relevance, top_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ndcg_from_ragas(ragas_dataset, k_pairs):\n",
        "    df = pd.DataFrame.from_dict(ragas_dataset)\n",
        "\n",
        "    # Extract the question and answer columns\n",
        "    questions = df['question']\n",
        "    answers = df['answer']\n",
        "\n",
        "    # Pair them into tuples\n",
        "    qa_pairs= list(zip(questions, answers))\n",
        "\n",
        "    questions = df['question']\n",
        "    ground_truths = df['ground_truths']\n",
        "\n",
        "    # Pair them into tuples\n",
        "\n",
        "    qgt_pairs = [(str(q), str(a)) for q, a in list(zip(questions, ground_truths))]\n",
        "    top_indices, rank_qa_pairs, top_pairs = rank_relevancy_pairs(qa_pairs, k_pairs)\n",
        "\n",
        "    top_indices, rank_qgt_pairs, top_pairs = rank_relevancy_pairs(qgt_pairs, k_pairs)\n",
        "\n",
        "\n",
        "    ndcg_score = ndcg(rank_qa_pairs, rank_qgt_pairs, k=k_pairs)\n",
        "    print(f\"NDCG Score: {ndcg_score}\")\n",
        "    return ndcg_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NDCG Score: 0.409057702101361\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.409057702101361"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ndcg_ragas= ndcg_from_ragas(ragas_dataset, 10)\n",
        "ndcg_ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## -------------------My test pipeline above here --------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyazkAIu85KL"
      },
      "source": [
        "### Ground Truth Dataset Creation Using GPT-3.5-turbo and GPT-4\n",
        "\n",
        "The next section might take you a long time to run, so the evaluation dataset is provided.\n",
        "\n",
        "The basic idea is that we can use LangChain to create questions based on our contexts, and then answer those questions.\n",
        "\n",
        "Let's look at how that works in the code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "V24T_gpPatAO"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "\n",
        "question_schema = ResponseSchema(\n",
        "    name=\"question\",\n",
        "    description=\"a question about the context.\"\n",
        ")\n",
        "\n",
        "question_response_schemas = [\n",
        "    question_schema,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ebbmazGrdPap"
      },
      "outputs": [],
      "source": [
        "question_output_parser = StructuredOutputParser.from_response_schemas(question_response_schemas)\n",
        "format_instructions = question_output_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qorL4TPGXJQ7"
      },
      "outputs": [],
      "source": [
        "question_generation_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
        "\n",
        "bare_prompt_template = \"{content}\"\n",
        "bare_template = ChatPromptTemplate.from_template(template=bare_prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "oPqC1_MXdRuh"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "qa_template = \"\"\"\\\n",
        "You are a University Professor creating a test for advanced students. For each context, create a question that is specific to the context. Avoid creating generic or general questions.\n",
        "\n",
        "question: a question about the context.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "question\n",
        "\n",
        "context: {context}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    context=docs[0],\n",
        "    format_instructions=format_instructions\n",
        ")\n",
        "\n",
        "question_generation_chain = bare_template | question_generation_llm\n",
        "\n",
        "response = question_generation_chain.invoke({\"content\" : messages})\n",
        "output_dict = question_output_parser.parse(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKFw9kyZd7eB",
        "outputId": "0ca79a32-1b8b-4a28-b98f-88e963b8ec1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "question\n",
            "What is the purpose of Form 10-K according to the United States Securities and Exchange Commission?\n"
          ]
        }
      ],
      "source": [
        "for k, v in output_dict.items():\n",
        "  print(k)\n",
        "  print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "dtASDdhLfd89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Users/hongtang/Documents/RAG_brewer/RAGenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "#genreeate questions based on the doc contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zolpr3CYeEYm",
        "outputId": "ac17aa41-3d3c-48f2-96d5-dfaaed94215a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.17it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "qac_triples = []\n",
        "\n",
        "for text in tqdm(docs[:10]):\n",
        "  messages = prompt_template.format_messages(\n",
        "      context=text,\n",
        "      format_instructions=format_instructions\n",
        "  )\n",
        "  response = question_generation_chain.invoke({\"content\" : messages}) # genrate questions\n",
        "  try:\n",
        "    output_dict = question_output_parser.parse(response.content) #question and answer\n",
        "  except Exception as e:\n",
        "    continue\n",
        "  output_dict[\"context\"] = text\n",
        "  qac_triples.append(output_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKBdQHK7Y2Vw",
        "outputId": "da731ac4-3281-4987-c91d-f36a9957b29a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the exact name of the registrant as specified in its charter?',\n",
              " 'context': Document(page_content='_ _ _ _ _ _ _ _ _ to _ _ _ _ _ _ _ _ _ commission file number : 001 - 34756 tesla, inc. ( exact name of registrant as specified in its charter ) delaware 91 - 2197729 ( state or other jurisdiction of incorporation or organization ) ( i. r. s.', metadata={'page_number': 1})}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pretty_print_dict_wrapped(qac_triples[6])\n",
        "qac_triples[6]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "vNB9Z2DrX2TC"
      },
      "outputs": [],
      "source": [
        "answer_generation_llm = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0)\n",
        "\n",
        "answer_schema = ResponseSchema(\n",
        "    name=\"answer\",\n",
        "    description=\"an answer to the question\"\n",
        ")\n",
        "\n",
        "answer_response_schemas = [\n",
        "    answer_schema,\n",
        "]\n",
        "\n",
        "answer_output_parser = StructuredOutputParser.from_response_schemas(answer_response_schemas)\n",
        "format_instructions = answer_output_parser.get_format_instructions()\n",
        "\n",
        "qa_template = \"\"\"\\\n",
        "You are a University Professor creating a test for advanced students. For each question and context, create an answer.\n",
        "\n",
        "answer: a answer about the context.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "answer\n",
        "\n",
        "question: {question}\n",
        "context: {context}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    context=qac_triples[0][\"context\"],\n",
        "    question=qac_triples[0][\"question\"],\n",
        "    format_instructions=format_instructions\n",
        ")\n",
        "\n",
        "answer_generation_chain = bare_template | answer_generation_llm\n",
        "\n",
        "response = answer_generation_chain.invoke({\"content\" : messages})\n",
        "output_dict = answer_output_parser.parse(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk-_lRR6fn5U",
        "outputId": "a8848b64-2ade-4e18-db4b-4f0f55cd96ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "answer\n",
            "The purpose of Form 10-K is to provide a comprehensive overview of a company's financial performance and operations for the fiscal year. It is an annual report required by the Securities and Exchange Commission (SEC) and must be filed by public companies to comply with federal securities laws. The form includes information about the company's financial condition, risk factors, management discussion and analysis, market information, corporate governance, executive compensation, and other relevant data.\n",
            "question\n",
            "What is the purpose of Form 10-K?\n"
          ]
        }
      ],
      "source": [
        "for k, v in output_dict.items():\n",
        "  print(k)\n",
        "  print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCdH0e9rrAKd",
        "outputId": "f9d598af-484f-4500-98af-04c71aca0962"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:37<00:00,  4.18s/it]\n"
          ]
        }
      ],
      "source": [
        "for triple in tqdm(qac_triples):\n",
        "  messages = prompt_template.format_messages(\n",
        "      context=triple[\"context\"],\n",
        "      question=triple[\"question\"],\n",
        "      format_instructions=format_instructions\n",
        "  )\n",
        "  response = answer_generation_chain.invoke({\"content\" : messages})\n",
        "  try:\n",
        "    output_dict = answer_output_parser.parse(response.content)\n",
        "  except Exception as e:\n",
        "    continue\n",
        "  triple[\"answer\"] = output_dict[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ground truth dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What is the purpose of Form 10-K?',\n",
              "  'context': Document(page_content='washington, d. c. 20549 form 10 - k ( mark one ) x annual report pursuant to section 13 or 15 ( d ) of the securities exchange act of 1934 for the fiscal year ended december 31, 2023 or o transition report pursuant to section 13 or 15 ( d ) of the', metadata={'page_number': 1}),\n",
              "  'answer': \"The purpose of Form 10-K is to provide a comprehensive overview of a company's financial performance and operations for the fiscal year. It is an annual report required by the Securities and Exchange Commission (SEC) and must be filed by public companies to comply with federal securities laws. The form includes information about the company's financial condition, risk factors, management discussion and analysis, market information, corporate governance, executive compensation, and other relevant data.\"},\n",
              " {'question': 'What type of report is being created in this context?',\n",
              "  'context': Document(page_content='x annual report pursuant to section 13 or 15 ( d ) of the securities exchange act of 1934 for the fiscal year ended december 31, 2023 or o transition report pursuant to section 13 or 15 ( d ) of the securities exchange act of 1934 for the transition', metadata={'page_number': 1}),\n",
              "  'answer': 'The type of report being created in this context is an annual report pursuant to section 13 or 15(d) of the Securities Exchange Act of 1934 for the fiscal year ended December 31, 2023, or a transition report pursuant to section 13 or 15(d) of the Securities Exchange Act of 1934 for the transition period specified within the document.'},\n",
              " {'question': 'What is the purpose of the Securities Exchange Act of 1934?',\n",
              "  'context': Document(page_content='of the securities exchange act of 1934 for the fiscal year ended december 31, 2023 or o transition report pursuant to section 13 or 15 ( d ) of the securities exchange act of 1934 for the transition period from _ _ _ _ _ _ _ _ _ to _ _ _ _ _ _ _ _ _', metadata={'page_number': 1}),\n",
              "  'answer': \"The purpose of the Securities Exchange Act of 1934 is to govern the secondary trading of securities (stocks, bonds, and debentures) in the United States. It established the Securities and Exchange Commission (SEC) to enforce federal securities laws; to regulate the securities industry, the nation's stock and options exchanges, and other activities and organizations, including the electronic securities markets in the United States. The Act also requires periodic reporting of information by companies with publicly traded securities.\"},\n",
              " {'question': 'What is the purpose of filing a transition report pursuant to section 13 or 15 (d) of the Securities Exchange Act of 1934?',\n",
              "  'context': Document(page_content='year ended december 31, 2023 or o transition report pursuant to section 13 or 15 ( d ) of the securities exchange act of 1934 for the transition period from _ _ _ _ _ _ _ _ _ to _ _ _ _ _ _ _ _ _ commission file number : 001 - 34756 tesla, inc. (', metadata={'page_number': 1}),\n",
              "  'answer': 'The purpose of filing a transition report pursuant to section 13 or 15(d) of the Securities Exchange Act of 1934 is to provide updated financial information and disclosures when a company is undergoing a transition period that does not align with its traditional fiscal year-end. This could be due to a change in the fiscal year or other significant corporate events that necessitate a different reporting period. The transition report ensures that investors and the Securities and Exchange Commission (SEC) have access to the latest financial data during the transition period.'},\n",
              " {'question': 'According to the Securities Exchange Act of 1934, what is the purpose of sections 13 and 15 (d)?',\n",
              "  'context': Document(page_content='pursuant to section 13 or 15 ( d ) of the securities exchange act of 1934 for the transition period from _ _ _ _ _ _ _ _ _ to _ _ _ _ _ _ _ _ _ commission file number : 001 - 34756 tesla, inc. ( exact name of registrant as specified in its charter )', metadata={'page_number': 1}),\n",
              "  'answer': \"Sections 13 and 15(d) of the Securities Exchange Act of 1934 primarily deal with periodic reporting requirements imposed on publicly traded companies. Section 13 requires that any company with securities traded on a national exchange or with assets exceeding a certain amount and a shareholder base above a specified size must file periodic reports, including annual (10-K) and quarterly (10-Q) reports, with the Securities and Exchange Commission (SEC). These reports provide detailed information about the company's financial condition, operations, and management. Section 15(d) imposes similar reporting requirements on companies that have filed a registration statement with the SEC, regardless of the number of their shareholders or the size of their assets, for as long as the registration statement is effective. The purpose of these sections is to ensure transparency and provide investors with the information necessary to make informed investment decisions.\"},\n",
              " {'question': 'What is the commission file number for Tesla, Inc. as specified in its charter?',\n",
              "  'context': Document(page_content='exchange act of 1934 for the transition period from _ _ _ _ _ _ _ _ _ to _ _ _ _ _ _ _ _ _ commission file number : 001 - 34756 tesla, inc. ( exact name of registrant as specified in its charter ) delaware 91 - 2197729 ( state or other jurisdiction', metadata={'page_number': 1}),\n",
              "  'answer': 'The commission file number for Tesla, Inc. as specified in its charter is 001-34756.'},\n",
              " {'question': 'What is the exact name of the registrant as specified in its charter?',\n",
              "  'context': Document(page_content='_ _ _ _ _ _ _ _ _ to _ _ _ _ _ _ _ _ _ commission file number : 001 - 34756 tesla, inc. ( exact name of registrant as specified in its charter ) delaware 91 - 2197729 ( state or other jurisdiction of incorporation or organization ) ( i. r. s.', metadata={'page_number': 1}),\n",
              "  'answer': 'Tesla, Inc.'},\n",
              " {'question': 'What is the exact name of the registrant as specified in its charter?',\n",
              "  'context': Document(page_content='file number : 001 - 34756 tesla, inc. ( exact name of registrant as specified in its charter ) delaware 91 - 2197729 ( state or other jurisdiction of incorporation or organization ) ( i. r. s. employer identification no. ) 1 tesla road austin, texas', metadata={'page_number': 1}),\n",
              "  'answer': 'Tesla, Inc.'},\n",
              " {'question': \"What is the address of Tesla's principal executive offices in Austin, Texas?\",\n",
              "  'context': Document(page_content='of registrant as specified in its charter ) delaware 91 - 2197729 ( state or other jurisdiction of incorporation or organization ) ( i. r. s. employer identification no. ) 1 tesla road austin, texas 78725 ( address of principal executive offices ) (', metadata={'page_number': 1}),\n",
              "  'answer': \"The address of Tesla's principal executive offices in Austin, Texas is 1 Tesla Road, Austin, Texas 78725.\"}]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qac_triples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "rrHXgH9Qs1ep"
      },
      "outputs": [],
      "source": [
        "# !pip install -q -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "uAvGGTyXsoHQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "ground_truth_qac_set = pd.DataFrame(qac_triples)\n",
        "ground_truth_qac_set[\"context\"] = ground_truth_qac_set[\"context\"].map(lambda x: str(x.page_content))\n",
        "ground_truth_qac_set = ground_truth_qac_set.rename(columns={\"answer\" : \"ground_truth\"})\n",
        "\n",
        "\n",
        "eval_dataset = Dataset.from_pandas(ground_truth_qac_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_FHUnAPVseB",
        "outputId": "25b4a640-1702-420c-84d0-be1cb41a57b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8CaCUeBVu4l",
        "outputId": "40b139ef-700e-4692-df40-90191322864d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the purpose of Form 10-K?',\n",
              " 'context': 'washington, d. c. 20549 form 10 - k ( mark one ) x annual report pursuant to section 13 or 15 ( d ) of the securities exchange act of 1934 for the fiscal year ended december 31, 2023 or o transition report pursuant to section 13 or 15 ( d ) of the',\n",
              " 'ground_truth': \"The purpose of Form 10-K is to provide a comprehensive overview of a company's financial performance and operations for the fiscal year. It is an annual report required by the Securities and Exchange Commission (SEC) and must be filed by public companies to comply with federal securities laws. The form includes information about the company's financial condition, risk factors, management discussion and analysis, market information, corporate governance, executive compensation, and other relevant data.\"}"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "d6ed993c7f4a4e4591176045bb206e4f",
            "650b6ff0350e42318d45836844fe7873",
            "b83306469dde499298362eca74e793a9",
            "f8aeba470272429aa4bdf66fd899fc64",
            "8953b8faf35d4e959ddd4d8c42c7d093",
            "479d7c515c3b42838fbd9bc6cd553263",
            "38d6278b104548deba0aa3fc60e62513",
            "40a907dc6d534106ab79040dce1a6085",
            "ce6c28a901fd42e9aa8b18224b0d97a6",
            "73107b08b99344e9b1fdbaddd82d8c55",
            "36ef058dcefd4babbea78b6d9301baff"
          ]
        },
        "id": "Nhp5X4M8zqrm",
        "outputId": "cea296a2-7613-4836-c0c0-9edac3a8bbf1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 110.14ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6114"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset.to_csv(\"groundtruth_eval_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Al5cagr-rvL"
      },
      "source": [
        "### Evaluating RAG Pipelines\n",
        "\n",
        "If you skipped ahead and need to load the `.csv` directly - uncomment the code below.\n",
        "\n",
        "If you're using Colab to do this notebook - please ensure you add it to your session files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "QJhes58R66-P"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 0 examples [00:00, ? examples/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 9 examples [00:00, 764.27 examples/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "eval_dataset = Dataset.from_csv(\"groundtruth_eval_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fAD8c_kthWc",
        "outputId": "ebf269a3-1bea-4c69-f046-70fc342172f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'context', 'ground_truth'],\n",
              "    num_rows: 9\n",
              "})"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load microsoft 10K and apply the selected pipeline\n",
        "# train test split. split the eval_dataset to 80/20 x\n",
        "# use the ground truth to evaluate different pipelines and select teh better one v\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqFYbjLK-6X7"
      },
      "source": [
        "### Evaluation Using RAGAS\n",
        "\n",
        "Now we can evaluate using RAGAS!\n",
        "\n",
        "The set-up is fairly straightforward - we simply need to create a dataset with our generated answers and our contexts, and then evaluate using the framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "1eBoHaf5t4w8"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    context_relevancy,\n",
        "    answer_correctness,\n",
        "    answer_similarity\n",
        ")\n",
        "\n",
        "from ragas.metrics.critique import harmfulness\n",
        "from ragas import evaluate\n",
        "\n",
        "def create_ragas_dataset(rag_pipeline, eval_dataset):\n",
        "  rag_dataset = []\n",
        "  for row in tqdm(eval_dataset):\n",
        "    answer = rag_pipeline.invoke({\"question\" : row[\"question\"]})\n",
        "    rag_dataset.append(\n",
        "        {\"question\" : row[\"question\"],\n",
        "         \"answer\" : answer[\"response\"].content,\n",
        "         \"contexts\" : [context.page_content for context in answer[\"context\"]],\n",
        "         \"ground_truths\" : [row[\"ground_truth\"]]\n",
        "         }\n",
        "    )\n",
        "  rag_df = pd.DataFrame(rag_dataset)\n",
        "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
        "  return rag_eval_dataset\n",
        "\n",
        "def evaluate_ragas_dataset(ragas_dataset):\n",
        "  result = evaluate(\n",
        "    ragas_dataset,\n",
        "    metrics=[\n",
        "        context_precision,\n",
        "        faithfulness,\n",
        "        answer_relevancy,\n",
        "        context_recall,\n",
        "        context_relevancy,\n",
        "        answer_correctness,\n",
        "        answer_similarity\n",
        "    ],\n",
        "  )\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4c4Jd8G_lXY"
      },
      "source": [
        "Lets create our dataset first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7oXgcjkuopO",
        "outputId": "7b3fda94-85fd-4dd3-8a8f-611ef21c3ee2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:06<00:00,  1.33it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "basic_qa_ragas_dataset = create_ragas_dataset(retrieval_augmented_qa_chain, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vv1NsRGZ6m5",
        "outputId": "c647ea11-4e85-465a-c24c-b751cc4558ea"
      },
      "outputs": [],
      "source": [
        "# pretty_print_dict_wrapped( basic_qa_ragas_dataset[0])\n",
        "# basic_qa_ragas_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obbgw3im_n01"
      },
      "source": [
        "Save it for later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "d94bd3a29d4a4ee099c8d7a8a778ee1e",
            "39fdac013acd4dbb946203dea1a9b7d0",
            "7d427c58085a46bbb4444cc5dabc3cc4",
            "dd6bdb0177684fdcb8927c2e9157504a",
            "fe30cf9c1e364ebda9370298d0892793",
            "35271b53be7c494199864401527d1aa1",
            "413dfaf7418245c3b0300af1f3c9d5e7",
            "0c4d147950b2442b90dc76a54cb33fc7",
            "fa5014b25c2340819fd3006aa79c16cc",
            "560abdecb8044bf8bf4a6e7ad1765ce0",
            "b627d46e60ac4966a5bb4ff62eb69e3a"
          ]
        },
        "id": "6FG8x4i3yZ2B",
        "outputId": "30a441a8-b65c-458b-aadc-ae04777543ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 195.51ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8602"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_ragas_dataset.to_csv(\"basic_qa_ragas_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5I_d_RT_pFr"
      },
      "source": [
        "And finally - evaluate how it did!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "0ae2c0380daf44eb8a7b3b21c30505de",
            "7fc3b1991f064973816da63da1cb2149",
            "7add80ce3dc0463c90674ff5d0ef71db",
            "d65792d371354cc0b2da2aff75147dea",
            "ea9873a0dd08471094eafbb8b371c5e9",
            "91e13ec26eb54c1ab92f16013c1f1d7b",
            "165bf14f29c24166bdc108d8fe3605a1",
            "1720d26c8f684ee881f971e0883da418",
            "757b1052457341d7be488325a6b5a39c",
            "13be715c18594004ab0d3882097aed4b",
            "c511529768b848a4b5ee5d6f5290e020"
          ]
        },
        "id": "ywp3Rwavy9pc",
        "outputId": "cba33fc3-4904-4c71-c900-13bd0122a8ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating:   8%|▊         | 5/63 [00:00<00:07,  8.21it/s]No statements were generated from the answer.\n",
            "No statements were generated from the answer.\n",
            "Evaluating:  11%|█         | 7/63 [00:02<00:18,  3.08it/s]No statements were generated from the answer.\n",
            "Evaluating:  33%|███▎      | 21/63 [00:03<00:07,  5.76it/s]No statements were generated from the answer.\n",
            "Evaluating:  49%|████▉     | 31/63 [00:04<00:03,  9.22it/s]No statements were generated from the answer.\n",
            "Evaluating: 100%|██████████| 63/63 [00:07<00:00,  8.44it/s]\n"
          ]
        }
      ],
      "source": [
        "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4oYnKTn15gY",
        "outputId": "652ca002-ecbe-4677-ca6b-3c2c07d254ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{     \"answer_correctness\": 0.4511098380111778,\n",
            "\"answer_relevancy\": 0.38902964973295784,     \"answer_similarity\":\n",
            "0.7822178154504189,     \"context_precision\": 0.7222222221833333,\n",
            "\"context_recall\": 0.7777777777777778,     \"context_relevancy\":\n",
            "0.07222222222222223,     \"faithfulness\": 1.0 }\n"
          ]
        }
      ],
      "source": [
        "pretty_print_dict_wrapped(basic_qa_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hyperparameter tunning\n",
        "# retrieval_augmented_qa_chain\n",
        "primary_qa_llm_gpt4o = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "rag_gpt4o_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | base_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | primary_qa_llm_gpt4o, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:09<00:00,  1.01s/it]\n",
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 386.68ba/s]\n",
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating:   8%|▊         | 5/63 [00:00<00:06,  9.00it/s]No statements were generated from the answer.\n",
            "Evaluating:  16%|█▌        | 10/63 [00:01<00:09,  5.80it/s]No statements were generated from the answer.\n",
            "Evaluating:  51%|█████     | 32/63 [00:03<00:01, 16.80it/s]No statements were generated from the answer.\n",
            "Evaluating:  56%|█████▌    | 35/63 [00:04<00:04,  5.92it/s]No statements were generated from the answer.\n",
            "Evaluating:  89%|████████▉ | 56/63 [00:06<00:00,  9.51it/s]No statements were generated from the answer.\n",
            "Evaluating: 100%|██████████| 63/63 [00:07<00:00,  8.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{     \"answer_correctness\": 0.4563945569982671,\n",
            "\"answer_relevancy\": 0.42863584865198795,     \"answer_similarity\":\n",
            "0.8255782279930683,     \"context_precision\": 0.7222222221833333,\n",
            "\"context_recall\": 0.7777777777777778,     \"context_relevancy\":\n",
            "0.07222222222222223,     \"faithfulness\": 1.0 }\n"
          ]
        }
      ],
      "source": [
        "rag_gpt4o_ragas_dataset = create_ragas_dataset(rag_gpt4o_chain, eval_dataset)\n",
        "rag_gpt4o_ragas_dataset.to_csv(\"rag_gpt4o_ragas_dataset.csv\")\n",
        "rag_gpt4o_result = evaluate_ragas_dataset(rag_gpt4o_ragas_dataset)\n",
        "pretty_print_dict_wrapped(rag_gpt4o_result )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "#chunk size sensitivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing Other Retrievers\n",
        "\n",
        "Now we can test our how changing our Retriever impacts our RAGAS evaluation!\n",
        "\n",
        "We'll build this simple qa_chain factory to create standardized qa_chains where the only different component will be the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_qa_chain(retriever):\n",
        "  primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "  created_qa_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever,\n",
        "     \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "    | RunnablePassthrough.assign(\n",
        "        context=itemgetter(\"context\")\n",
        "      )\n",
        "    | {\n",
        "         \"response\": prompt | primary_qa_llm,\n",
        "         \"context\": itemgetter(\"context\"),\n",
        "      }\n",
        "  )\n",
        "\n",
        "  return created_qa_chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOPp4Xq7AvEx"
      },
      "source": [
        "#### Parent Document Retriever\n",
        "\n",
        "One of the easier ways we can imagine improving a retriever is to embed our documents into small chunks, and then retrieve a significant amount of additional context that \"surrounds\" the found context.\n",
        "\n",
        "You can read more about this method [here](https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever)!\n",
        "\n",
        "The basic outline of this retrieval method is as follows:\n",
        "\n",
        "1. Obtain User Question\n",
        "2. Retrieve child documents using Dense Vector Retrieval\n",
        "3. Merge the child documents based on their parents. If they have the same parents - they become merged.\n",
        "4. Replace the child documents with their respective parent documents from an in-memory-store.\n",
        "5. Use the parent documents to augment generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "67I6QJAJ0Un7"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb Cell 69\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y320sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m parent_document_retriever \u001b[39m=\u001b[39m ParentDocumentRetriever(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y320sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     vectorstore\u001b[39m=\u001b[39mvectorstore,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y320sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     docstore\u001b[39m=\u001b[39mstore,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y320sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     child_splitter\u001b[39m=\u001b[39mchild_splitter,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y320sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     parent_splitter\u001b[39m=\u001b[39mparent_splitter,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y320sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y320sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Add documents to the ParentDocumentRetriever\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y320sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m parent_document_retriever\u001b[39m.\u001b[39;49madd_documents(documents)\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/langchain/retrievers/parent_document_retriever.py:122\u001b[0m, in \u001b[0;36mParentDocumentRetriever.add_documents\u001b[0;34m(self, documents, ids, add_to_docstore)\u001b[0m\n\u001b[1;32m    120\u001b[0m     docs\u001b[39m.\u001b[39mextend(sub_docs)\n\u001b[1;32m    121\u001b[0m     full_docs\u001b[39m.\u001b[39mappend((_id, doc))\n\u001b[0;32m--> 122\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49madd_documents(docs)\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m add_to_docstore:\n\u001b[1;32m    124\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocstore\u001b[39m.\u001b[39mmset(full_docs)\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/langchain_core/vectorstores.py:138\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    137\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 138\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_texts(texts, metadatas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:276\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m texts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(texts)\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents(texts)\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m metadatas:\n\u001b[1;32m    278\u001b[0m     \u001b[39m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[39m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     length_diff \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(metadatas)\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/langchain_community/embeddings/openai.py:668\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m engine \u001b[39m=\u001b[39m cast(\u001b[39mstr\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeployment)\n\u001b[0;32m--> 668\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49mengine)\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/langchain_community/embeddings/openai.py:494\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    492\u001b[0m batched_embeddings: List[List[\u001b[39mfloat\u001b[39m]] \u001b[39m=\u001b[39m []\n\u001b[1;32m    493\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 494\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    495\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    496\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    497\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    499\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    500\u001b[0m         response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mdict()\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/langchain_community/embeddings/openai.py:116\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m retry_decorator \u001b[39m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[1;32m    119\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/openai/resources/embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m         embedding\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(  \u001b[39m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             base64\u001b[39m.\u001b[39mb64decode(data), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    115\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    116\u001b[0m     body\u001b[39m=\u001b[39;49mmaybe_transform(params, embedding_create_params\u001b[39m.\u001b[39;49mEmbeddingCreateParams),\n\u001b[1;32m    117\u001b[0m     options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    118\u001b[0m         extra_headers\u001b[39m=\u001b[39;49mextra_headers,\n\u001b[1;32m    119\u001b[0m         extra_query\u001b[39m=\u001b[39;49mextra_query,\n\u001b[1;32m    120\u001b[0m         extra_body\u001b[39m=\u001b[39;49mextra_body,\n\u001b[1;32m    121\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    122\u001b[0m         post_parser\u001b[39m=\u001b[39;49mparser,\n\u001b[1;32m    123\u001b[0m     ),\n\u001b[1;32m    124\u001b[0m     cast_to\u001b[39m=\u001b[39;49mCreateEmbeddingResponse,\n\u001b[1;32m    125\u001b[0m )\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    922\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    923\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    924\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    925\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    926\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    927\u001b[0m     )\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/openai/_base_client.py:952\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    949\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mSending HTTP Request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mmethod, request\u001b[39m.\u001b[39murl)\n\u001b[1;32m    951\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 952\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    953\u001b[0m         request,\n\u001b[1;32m    954\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    955\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    957\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    958\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEncountered httpx.TimeoutException\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, Iterable)\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[39m=\u001b[39m pool_request\u001b[39m.\u001b[39mwait_for_connection(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[39m.\u001b[39mclear_connection()\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_failed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_stream\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
            "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
            "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1102\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# Convert base_docs to a list of Document objects\n",
        "documents = [Document(page_content=doc['content'], metadata=doc['metadata']) for doc in base_docs]\n",
        "\n",
        "# Initialize text splitters\n",
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1500)\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
        "\n",
        "# Initialize the vector store\n",
        "vectorstore = Chroma(collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings())\n",
        "\n",
        "# Initialize the in-memory document store\n",
        "store = InMemoryStore()\n",
        "\n",
        "# Initialize the ParentDocumentRetriever\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        ")\n",
        "\n",
        "# Add documents to the ParentDocumentRetriever\n",
        "parent_document_retriever.add_documents(documents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTH0MDolBndm"
      },
      "source": [
        "Let's create, test, and then evaluate our new chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "KMjLfqOC09Iw"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever_qa_chain = create_qa_chain(parent_document_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rv8bAHPN1H4P",
        "outputId": "431c63b5-8e19-4ab8-be58-f41eb4a23645"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Answer: Retrieval-augmented generation (RAG) is a practicable complement to large language models (LLMs) that relies heavily on the relevance of retrieved documents to improve the robustness of generation.'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retriever_qa_chain.invoke({\"question\" : \"What is RAG?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQJRIQmU1WTw",
        "outputId": "9f4fcb50-6d79-48bc-d5b3-eaa345c6e1a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:10<00:00,  1.10s/it]\n"
          ]
        }
      ],
      "source": [
        "pdr_qa_ragas_dataset = create_ragas_dataset(parent_document_retriever_qa_chain, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "5dd26fa20b5149cbada24a14be27787b",
            "a137c75d07e94f4ab7143888253b3bc6",
            "f4f08a39a19a4863914582396a8f5a16",
            "bd4c916b33aa405f9769d2e4dd3149c9",
            "f75eeddbab3448b6b924b755ff2fd5cc",
            "dd09af1b4aa64b548338f22fcd178e19",
            "4387da5e92eb47428db67b8389f05653",
            "08f2586e24e44f14aca693139ed0d595",
            "65112c5001d64b52be9f1e913ab21157",
            "2ad6efc78a0e4d16b84007b95567862f",
            "f89aedf49eca4780b591b3ece7642d95"
          ]
        },
        "id": "d9vfKnCL1jtB",
        "outputId": "2df426dd-940c-4afb-a991-7949f60d6205"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 306.38ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "55684"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr_qa_ragas_dataset.to_csv(\"pdr_qa_ragas_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "bab61da16bfe4f568923c87c1bb8c66a",
            "201c99e587f3474eb304704979543738",
            "0dacebb0647e4493bc4ed015dffa0f64",
            "5fda12ebfac34d3793ad8a627db3ad65",
            "692d030e5d394c1d9ba40486a93bd107",
            "45e7cb340c934f4abff25f5dea42a05e",
            "6afd402d0b7d4a5dada6bba96b738364",
            "5e08dd36706446e198ecd23154119393",
            "ef40d89b20f54ebd9f86d669411c988a",
            "7feeb0d0abb14b009e3d91fd6e499cc8",
            "86c61500b12a4ec6b921c46bf3226348"
          ]
        },
        "id": "qfB1H9S_1mW3",
        "outputId": "f25b1e3b-f20c-4c57-b2a8-e4015eb7868b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating: 100%|██████████| 70/70 [01:30<00:00,  1.29s/it]\n"
          ]
        }
      ],
      "source": [
        "pdr_qa_result = evaluate_ragas_dataset(pdr_qa_ragas_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nFyYCdL2Nco",
        "outputId": "dfa7b2d8-bb05-4e55-ef1e-f18870e62efa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.9806, 'faithfulness': 0.9500, 'answer_relevancy': 0.9600, 'context_recall': 1.0000, 'context_relevancy': 0.0338, 'answer_correctness': 0.6026, 'answer_similarity': 0.9366}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaNk6o7_BqX8"
      },
      "source": [
        "#### Ensemble Retrieval\n",
        "\n",
        "Next let's look at ensemble retrieval!\n",
        "\n",
        "You can read more about this [here](https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble)!\n",
        "\n",
        "The basic idea is as follows:\n",
        "\n",
        "1. Obtain User Question\n",
        "2. Hit the Retriever Pair\n",
        "    - Retrieve Documents with BM25 Sparse Vector Retrieval\n",
        "    - Retrieve Documents with Dense Vector Retrieval Method\n",
        "3. Collect and \"fuse\" the retrieved docs based on their weighting using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm into a single ranked list.\n",
        "4. Use those documents to augment our generation.\n",
        "\n",
        "Ensure your `weights` list - the relative weighting of each retriever - sums to 1!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "zz7dl1GD5-L-"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# Assuming base_docs is a list of dictionaries with 'content' and 'metadata' keys\n",
        "# Convert base_docs to a list of Document objects\n",
        "documents = [Document(page_content=doc['content'], metadata=doc['metadata']) for doc in base_docs]\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=450, chunk_overlap=75)\n",
        "\n",
        "# Split the documents\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Initialize the BM25 retriever\n",
        "bm25_retriever = BM25Retriever.from_documents(docs)\n",
        "bm25_retriever.k = 2\n",
        "\n",
        "# Initialize the embeddings and vector store\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(docs, embedding)\n",
        "\n",
        "# Initialize the Chroma retriever\n",
        "chroma_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# Initialize the Ensemble retriever\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, chroma_retriever], weights=[0.75, 0.25])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "Vs8wxT9b5pRA"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'page_content'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb Cell 81\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrievers\u001b[39;00m \u001b[39mimport\u001b[39;00m BM25Retriever, EnsembleRetriever\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y131sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text_splitter \u001b[39m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[39m=\u001b[39m\u001b[39m450\u001b[39m, chunk_overlap\u001b[39m=\u001b[39m\u001b[39m75\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y131sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m docs \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39;49msplit_documents(base_docs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y131sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m bm25_retriever \u001b[39m=\u001b[39m BM25Retriever\u001b[39m.\u001b[39mfrom_documents(docs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hongtang/Documents/RAG_brewer/code/Ragas_GroundTruthGenerator.ipynb#Y131sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m bm25_retriever\u001b[39m.\u001b[39mk \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n",
            "File \u001b[0;32m~/Documents/RAG_brewer/RAGenv/lib/python3.9/site-packages/langchain_text_splitters/base.py:93\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m     91\u001b[0m texts, metadatas \u001b[39m=\u001b[39m [], []\n\u001b[1;32m     92\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents:\n\u001b[0;32m---> 93\u001b[0m     texts\u001b[39m.\u001b[39mappend(doc\u001b[39m.\u001b[39;49mpage_content)\n\u001b[1;32m     94\u001b[0m     metadatas\u001b[39m.\u001b[39mappend(doc\u001b[39m.\u001b[39mmetadata)\n\u001b[1;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_documents(texts, metadatas\u001b[39m=\u001b[39mmetadatas)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'page_content'"
          ]
        }
      ],
      "source": [
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=450, chunk_overlap=75)\n",
        "docs = text_splitter.split_documents(base_docs)\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(docs)\n",
        "bm25_retriever.k = 2\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(docs, embedding)\n",
        "chroma_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, chroma_retriever], weights=[0.75, 0.25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cv69YDpF6PrJ"
      },
      "outputs": [],
      "source": [
        "ensemble_retriever_qa_chain = create_qa_chain(ensemble_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6lSszzrf6UmP",
        "outputId": "21f43fd0-3d42-42f0-f8a2-160e5160ac4c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Retrieval Augmented Generation (RAG) is a practicable complement to Large Language Models (LLMs) that relies heavily on the relevance of retrieved documents.'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retriever_qa_chain.invoke({\"question\" : \"What is RAG?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abUgTGDT6UrV",
        "outputId": "bf3f3d19-6850-449b-b35a-fa778ef22a6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:13<00:00,  1.34s/it]\n"
          ]
        }
      ],
      "source": [
        "ensemble_qa_ragas_dataset = create_ragas_dataset(ensemble_retriever_qa_chain, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "59effa0dc7ca4ddba0edb737cb2018b6",
            "d029bd90b3964a208fdc438b64358c61",
            "1621e3ba16ad4bff875395b3a57b9822",
            "0b0141b9f8bb4cb7bded625cac02bd88",
            "fafdda649edb402b9150ee8c0d219de5",
            "d98d5b5166574048b349ed5e64c4fccd",
            "99a3af6f7f4141bdb20c303c7ea36d95",
            "7a057f744731493a9163e4ef5f762cdf",
            "c0353b4d6e064ee5894a8e735751bebd",
            "be7b85350cf8452cbed956637bb0ea2f",
            "5841b3f2f95547a894622dbfca41e079"
          ]
        },
        "id": "bGHipYsf7phk",
        "outputId": "b204f31d-cf3f-41bd-d0e5-a977eba1f8e8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59effa0dc7ca4ddba0edb737cb2018b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "24578"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_ragas_dataset.to_csv(\"ensemble_qa_ragas_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "9d3cdc6e24114b4985c203b7aa2c1ab5",
            "9f99ce42536144eeae0939ec2231c5b3",
            "e255ee180dcf484f9bad86a509f6f96d",
            "9c412cfedfcb424a96d24a93cebbf964",
            "52a1402d9c0549f6810893361fc54ea2",
            "a6775c9f72e9457a96b1fd726281d96e",
            "701b793b9b4640518968a87d9c39d703",
            "275a420d960041ff977a5729ad27bc6d",
            "3ae0be79205340c4906e69be2d7f1e7f",
            "7d67f4a07b7c4c5f974f2adec1c2c4a4",
            "b674a1af62b04ac490f08966030ca8c6"
          ]
        },
        "id": "Ozo0jkvx7r1d",
        "outputId": "6d58a03e-6f6d-4836-9fd7-53e0bd1df9e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:ragas.validation:passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d3cdc6e24114b4985c203b7aa2c1ab5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ensemble_qa_result = evaluate_ragas_dataset(ensemble_qa_ragas_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvabdcbh793a",
        "outputId": "a177e956-f4df-4e8d-a32e-ac9b95257894"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.7746, 'faithfulness': 1.0000, 'answer_relevancy': 0.8441, 'context_recall': 1.0000, 'context_relevancy': 0.0325, 'answer_correctness': 0.6255, 'answer_similarity': 0.9327}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4vXVWqiCcSI"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "Observe your results in a table!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmBoVQ5hV3Kc",
        "outputId": "fa8c67e8-ee61-4fc8-9c26-8e119bf67e06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.9000, 'faithfulness': 0.8500, 'answer_relevancy': 0.9651, 'context_recall': 0.7000, 'context_relevancy': 0.1051, 'answer_correctness': 0.5615, 'answer_similarity': 0.9298}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax1JLXKxUsXF",
        "outputId": "9c4436ca-53e9-4faa-acab-543baa8cc6e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.9806, 'faithfulness': 0.9500, 'answer_relevancy': 0.9600, 'context_recall': 1.0000, 'context_relevancy': 0.0338, 'answer_correctness': 0.6026, 'answer_similarity': 0.9366}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr_qa_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drxLlO3zUpyQ",
        "outputId": "5721b341-a93f-430a-a4ca-72f070bec691"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.7746, 'faithfulness': 1.0000, 'answer_relevancy': 0.8441, 'context_recall': 1.0000, 'context_relevancy': 0.0325, 'answer_correctness': 0.6255, 'answer_similarity': 0.9327}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6YPGf-2l0Kx"
      },
      "source": [
        "We can also zoom in on each result and find specific information about each of the questions and answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "SkxLtk43ikka"
      },
      "outputs": [],
      "source": [
        "ensemble_qa_result_df = ensemble_qa_result.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3JZMhUg3jSvE",
        "outputId": "13f61824-f184-46bd-b6ae-9f8355e405a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"ensemble_qa_result_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What is the main focus of this paper?\",\n          \"What is the purpose of this paper?\",\n          \"What is the aim of this paper?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"The main focus of the paper 'A Survey on Retrieval-Augmented Text Generation' is to conduct a survey about retrieval-augmented text generation, highlighting the generic paradigm of retrieval-augmented generation and reviewing notable approaches for different tasks in the field of computational linguistics.\",\n          \"The main focus of this paper is to improve the robustness of generation in large language models through Corrective Retrieval Augmented Generation (CRAG).\",\n          \"The purpose of this paper is to propose the Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation in large language models.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truths\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"The main focus of the paper 'A Survey on Retrieval-Augmented Text Generation' is to conduct a comprehensive survey about retrieval-augmented text generation in the field of computational linguistics. It highlights the generic paradigm of retrieval-augmented generation, reviews notable approaches across various NLP tasks such as dialogue response generation and machine translation, and discusses the advantages of this method over conventional generation models. Additionally, the paper identifies important future research directions in this area.\",\n          \"The main focus of the paper 'A Survey on Retrieval-Augmented Text Generation' is to conduct a comprehensive survey on the topic of retrieval-augmented text generation, which has gained increasing attention in the computational linguistics community. The paper highlights the generic paradigm of retrieval-augmented generation models, reviews notable approaches across various natural language processing tasks such as dialogue response generation and machine translation, and discusses the state-of-the-art performance achieved by these models. Additionally, the paper identifies and suggests important future research directions in this field.\",\n          \"The focus of this paper is on retrieval-augmented text generation within the field of computational linguistics. It aims to provide a comprehensive survey of the state-of-the-art performance of retrieval-augmented text generation models in various NLP tasks, discuss the generic paradigm of such models, review notable approaches across different tasks such as dialogue response generation and machine translation, and identify important future research directions.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11333622679572332,\n        \"min\": 0.6791666666496875,\n        \"max\": 0.9999999999,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9999999999,\n          0.699999999965,\n          0.8041666666465626\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13422285843245738,\n        \"min\": 0.7375829574255018,\n        \"max\": 0.9999999999999991,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7376765475827488\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.031256775905122644,\n        \"min\": 0.0,\n        \"max\": 0.06976744186046512,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14092752325141047,\n        \"min\": 0.47302903353519454,\n        \"max\": 0.9115925259582953,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.698100661027582\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.051353857017640614,\n        \"min\": 0.876011245407071,\n        \"max\": 0.992402644110328,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.992402644110328\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "ensemble_qa_result_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4024e3de-daef-4c5d-9ed8-6fda93735160\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truths</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_relevancy</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>answer_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the main focus of the paper 'A Survey ...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>[A Survey on Retrieval-Augmented Text Generati...</td>\n",
              "      <td>[The main focus of the paper 'A Survey on Retr...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.581007</td>\n",
              "      <td>0.990696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the main focus of the paper 'A Survey ...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>[A Survey on Retrieval-Augmented Text Generati...</td>\n",
              "      <td>[The main focus of the paper 'A Survey on Retr...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.581211</td>\n",
              "      <td>0.991511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the main focus of this paper?</td>\n",
              "      <td>The main focus of this paper is to improve the...</td>\n",
              "      <td>[and main intent within questions.\\nquestion: ...</td>\n",
              "      <td>[The main focus of this paper is to conduct a ...</td>\n",
              "      <td>The main focus of this paper is to conduct a s...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.737677</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.722210</td>\n",
              "      <td>0.888841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the main focus of the paper 'A Survey ...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>[A Survey on Retrieval-Augmented Text Generati...</td>\n",
              "      <td>[The main focus of the paper 'A Survey on Retr...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.622440</td>\n",
              "      <td>0.989762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the aim of this paper?</td>\n",
              "      <td>The aim of this paper is to propose Corrective...</td>\n",
              "      <td>[and main intent within questions.\\nquestion: ...</td>\n",
              "      <td>[The aim of this paper is to conduct a survey ...</td>\n",
              "      <td>The aim of this paper is to conduct a survey a...</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.737583</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.473361</td>\n",
              "      <td>0.893446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is the focus of this paper?</td>\n",
              "      <td>The focus of this paper is to improve the robu...</td>\n",
              "      <td>[and main intent within questions.\\nquestion: ...</td>\n",
              "      <td>[The focus of this paper is on retrieval-augme...</td>\n",
              "      <td>The focus of this paper is on retrieval-augmen...</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.745384</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.911593</td>\n",
              "      <td>0.919097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the main focus of this paper?</td>\n",
              "      <td>The main focus of this paper is to improve the...</td>\n",
              "      <td>[and main intent within questions.\\nquestion: ...</td>\n",
              "      <td>[The main focus of this paper is to conduct a ...</td>\n",
              "      <td>The main focus of this paper is to conduct a s...</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.737677</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.719003</td>\n",
              "      <td>0.876011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the purpose of this paper?</td>\n",
              "      <td>The purpose of this paper is to propose the Co...</td>\n",
              "      <td>[and main intent within questions.\\nquestion: ...</td>\n",
              "      <td>[The purpose of this paper is to conduct a com...</td>\n",
              "      <td>The purpose of this paper is to conduct a comp...</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.741192</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.473029</td>\n",
              "      <td>0.892116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the main focus of the paper 'A Survey ...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>[A Survey on Retrieval-Augmented Text Generati...</td>\n",
              "      <td>[The main focus of the paper 'A Survey on Retr...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.698101</td>\n",
              "      <td>0.992403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What is the purpose of this paper?</td>\n",
              "      <td>The purpose of this paper is to propose the Co...</td>\n",
              "      <td>[and main intent within questions.\\nquestion: ...</td>\n",
              "      <td>[The purpose of this paper is to conduct a com...</td>\n",
              "      <td>The purpose of this paper is to conduct a comp...</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.741192</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.473232</td>\n",
              "      <td>0.892926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4024e3de-daef-4c5d-9ed8-6fda93735160')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4024e3de-daef-4c5d-9ed8-6fda93735160 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4024e3de-daef-4c5d-9ed8-6fda93735160');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-731f3088-d5c3-4569-8b16-970864fa9658\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-731f3088-d5c3-4569-8b16-970864fa9658')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-731f3088-d5c3-4569-8b16-970864fa9658 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0458f63d-8180-4a51-b299-7485f6232336\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ensemble_qa_result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0458f63d-8180-4a51-b299-7485f6232336 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ensemble_qa_result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What is the main focus of the paper 'A Survey ...   \n",
              "1  What is the main focus of the paper 'A Survey ...   \n",
              "2              What is the main focus of this paper?   \n",
              "3  What is the main focus of the paper 'A Survey ...   \n",
              "4                     What is the aim of this paper?   \n",
              "5                   What is the focus of this paper?   \n",
              "6              What is the main focus of this paper?   \n",
              "7                 What is the purpose of this paper?   \n",
              "8  What is the main focus of the paper 'A Survey ...   \n",
              "9                 What is the purpose of this paper?   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The main focus of the paper 'A Survey on Retri...   \n",
              "1  The main focus of the paper 'A Survey on Retri...   \n",
              "2  The main focus of this paper is to improve the...   \n",
              "3  The main focus of the paper 'A Survey on Retri...   \n",
              "4  The aim of this paper is to propose Corrective...   \n",
              "5  The focus of this paper is to improve the robu...   \n",
              "6  The main focus of this paper is to improve the...   \n",
              "7  The purpose of this paper is to propose the Co...   \n",
              "8  The main focus of the paper 'A Survey on Retri...   \n",
              "9  The purpose of this paper is to propose the Co...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [A Survey on Retrieval-Augmented Text Generati...   \n",
              "1  [A Survey on Retrieval-Augmented Text Generati...   \n",
              "2  [and main intent within questions.\\nquestion: ...   \n",
              "3  [A Survey on Retrieval-Augmented Text Generati...   \n",
              "4  [and main intent within questions.\\nquestion: ...   \n",
              "5  [and main intent within questions.\\nquestion: ...   \n",
              "6  [and main intent within questions.\\nquestion: ...   \n",
              "7  [and main intent within questions.\\nquestion: ...   \n",
              "8  [A Survey on Retrieval-Augmented Text Generati...   \n",
              "9  [and main intent within questions.\\nquestion: ...   \n",
              "\n",
              "                                       ground_truths  \\\n",
              "0  [The main focus of the paper 'A Survey on Retr...   \n",
              "1  [The main focus of the paper 'A Survey on Retr...   \n",
              "2  [The main focus of this paper is to conduct a ...   \n",
              "3  [The main focus of the paper 'A Survey on Retr...   \n",
              "4  [The aim of this paper is to conduct a survey ...   \n",
              "5  [The focus of this paper is on retrieval-augme...   \n",
              "6  [The main focus of this paper is to conduct a ...   \n",
              "7  [The purpose of this paper is to conduct a com...   \n",
              "8  [The main focus of the paper 'A Survey on Retr...   \n",
              "9  [The purpose of this paper is to conduct a com...   \n",
              "\n",
              "                                        ground_truth  context_precision  \\\n",
              "0  The main focus of the paper 'A Survey on Retri...           0.679167   \n",
              "1  The main focus of the paper 'A Survey on Retri...           0.679167   \n",
              "2  The main focus of this paper is to conduct a s...           1.000000   \n",
              "3  The main focus of the paper 'A Survey on Retri...           0.679167   \n",
              "4  The aim of this paper is to conduct a survey a...           0.804167   \n",
              "5  The focus of this paper is on retrieval-augmen...           0.916667   \n",
              "6  The main focus of this paper is to conduct a s...           0.700000   \n",
              "7  The purpose of this paper is to conduct a comp...           0.804167   \n",
              "8  The main focus of the paper 'A Survey on Retri...           0.679167   \n",
              "9  The purpose of this paper is to conduct a comp...           0.804167   \n",
              "\n",
              "   faithfulness  answer_relevancy  context_recall  context_relevancy  \\\n",
              "0           1.0          1.000000             1.0           0.055556   \n",
              "1           1.0          1.000000             1.0           0.055556   \n",
              "2           1.0          0.737677             1.0           0.000000   \n",
              "3           1.0          1.000000             1.0           0.055556   \n",
              "4           1.0          0.737583             1.0           0.000000   \n",
              "5           1.0          0.745384             1.0           0.000000   \n",
              "6           1.0          0.737677             1.0           0.000000   \n",
              "7           1.0          0.741192             1.0           0.069767   \n",
              "8           1.0          1.000000             1.0           0.018519   \n",
              "9           1.0          0.741192             1.0           0.069767   \n",
              "\n",
              "   answer_correctness  answer_similarity  \n",
              "0            0.581007           0.990696  \n",
              "1            0.581211           0.991511  \n",
              "2            0.722210           0.888841  \n",
              "3            0.622440           0.989762  \n",
              "4            0.473361           0.893446  \n",
              "5            0.911593           0.919097  \n",
              "6            0.719003           0.876011  \n",
              "7            0.473029           0.892116  \n",
              "8            0.698101           0.992403  \n",
              "9            0.473232           0.892926  "
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jXR7ckel-v8"
      },
      "source": [
        "We'll also look at combining the results and looking at them in a single table so we can make inferences about them!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "BE5KKE_JkcD3"
      },
      "outputs": [],
      "source": [
        "def create_df_dict(pipeline_name, pipeline_items):\n",
        "  df_dict = {\"name\" : pipeline_name}\n",
        "  for name, score in pipeline_items:\n",
        "    df_dict[name] = score\n",
        "  return df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "L1mPqYdqk4iQ"
      },
      "outputs": [],
      "source": [
        "basic_rag_df_dict = create_df_dict(\"basic_rag\", basic_qa_result.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "ntJPzwy9lI46"
      },
      "outputs": [],
      "source": [
        "pdr_rag_df_dict = create_df_dict(\"pdr_rag\", pdr_qa_result.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "R0fkbIQElPza"
      },
      "outputs": [],
      "source": [
        "ensemble_rag_df_dict = create_df_dict(\"ensemble_rag\", ensemble_qa_result.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Bc4T1E83lVbE"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame([basic_rag_df_dict, pdr_rag_df_dict, ensemble_rag_df_dict])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "cv_9wNYGlibg",
        "outputId": "4c626b77-1d41-4285-9d57-0f373352e8fd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ensemble_rag\",\n          \"pdr_rag\",\n          \"basic_rag\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10379715324506933,\n        \"min\": 0.7745833333039549,\n        \"max\": 0.9805555555220369,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7745833333039549,\n          0.9805555555220369,\n          0.89999999994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07637626158259735,\n        \"min\": 0.85,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          0.95,\n          0.85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06847601558156698,\n        \"min\": 0.8440704012948282,\n        \"max\": 0.9651479932438057,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8440704012948282,\n          0.9600353343858317,\n          0.9651479932438057\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17320508075688776,\n        \"min\": 0.7,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0415509855251123,\n        \"min\": 0.03247200689061154,\n        \"max\": 0.10510489510489511,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.03247200689061154,\n          0.0338198814450419\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03246279111575617,\n        \"min\": 0.561453126419461,\n        \"max\": 0.6255187325449345,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6255187325449345,\n          0.6026071687021405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003424163298641312,\n        \"min\": 0.9297575144358856,\n        \"max\": 0.9365825209624082,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9326809907857985,\n          0.9365825209624082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7ab25ad5-0d99-4dd8-9fb3-d51567ac4bb6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_relevancy</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>answer_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ensemble_rag</td>\n",
              "      <td>0.774583</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.844070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.032472</td>\n",
              "      <td>0.625519</td>\n",
              "      <td>0.932681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pdr_rag</td>\n",
              "      <td>0.980556</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.960035</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.033820</td>\n",
              "      <td>0.602607</td>\n",
              "      <td>0.936583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>basic_rag</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.965148</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.105105</td>\n",
              "      <td>0.561453</td>\n",
              "      <td>0.929758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ab25ad5-0d99-4dd8-9fb3-d51567ac4bb6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ab25ad5-0d99-4dd8-9fb3-d51567ac4bb6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ab25ad5-0d99-4dd8-9fb3-d51567ac4bb6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6626d30b-abee-453b-a230-a430972c6906\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6626d30b-abee-453b-a230-a430972c6906')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6626d30b-abee-453b-a230-a430972c6906 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           name  context_precision  faithfulness  answer_relevancy  \\\n",
              "2  ensemble_rag           0.774583          1.00          0.844070   \n",
              "1       pdr_rag           0.980556          0.95          0.960035   \n",
              "0     basic_rag           0.900000          0.85          0.965148   \n",
              "\n",
              "   context_recall  context_relevancy  answer_correctness  answer_similarity  \n",
              "2             1.0           0.032472            0.625519           0.932681  \n",
              "1             1.0           0.033820            0.602607           0.936583  \n",
              "0             0.7           0.105105            0.561453           0.929758  "
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df.sort_values(\"answer_correctness\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPocfrNFiYWi"
      },
      "source": [
        "### ❓QUESTION❓\n",
        "\n",
        "What conclusions can you draw about the above results?\n",
        "\n",
        "Describe in your own words what the metrics are expressing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "fbhz-vD4JPtN",
        "outputId": "d1c8d5fc-ac40-4205-c282-9cef49744bbc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'RunnableParallel' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-6b461eff8be0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m retrieval_augmented_qa_chain = (\n\u001b[0;32m----> 2\u001b[0;31m     RunnableParallel({\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;34m'context'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbase_retriever\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m'question'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRunnablePassthrough\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     }) | {\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RunnableParallel' is not defined"
          ]
        }
      ],
      "source": [
        "retrieval_augmented_qa_chain = (\n",
        "    RunnableParallel({\n",
        "        'context': itemgetter('question') | base_retriever,\n",
        "        'question': RunnablePassthrough()\n",
        "    }) | {\n",
        "        'response': prompt | primary_qa_llm | parser,\n",
        "        'context': itemgetter('context')\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16poQFuuz56T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rag_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08f2586e24e44f14aca693139ed0d595": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae2c0380daf44eb8a7b3b21c30505de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fc3b1991f064973816da63da1cb2149",
              "IPY_MODEL_7add80ce3dc0463c90674ff5d0ef71db",
              "IPY_MODEL_d65792d371354cc0b2da2aff75147dea"
            ],
            "layout": "IPY_MODEL_ea9873a0dd08471094eafbb8b371c5e9"
          }
        },
        "0b0141b9f8bb4cb7bded625cac02bd88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be7b85350cf8452cbed956637bb0ea2f",
            "placeholder": "​",
            "style": "IPY_MODEL_5841b3f2f95547a894622dbfca41e079",
            "value": " 1/1 [00:00&lt;00:00, 27.69ba/s]"
          }
        },
        "0c4d147950b2442b90dc76a54cb33fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dacebb0647e4493bc4ed015dffa0f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e08dd36706446e198ecd23154119393",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef40d89b20f54ebd9f86d669411c988a",
            "value": 70
          }
        },
        "13be715c18594004ab0d3882097aed4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1621e3ba16ad4bff875395b3a57b9822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a057f744731493a9163e4ef5f762cdf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0353b4d6e064ee5894a8e735751bebd",
            "value": 1
          }
        },
        "165bf14f29c24166bdc108d8fe3605a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1720d26c8f684ee881f971e0883da418": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "201c99e587f3474eb304704979543738": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45e7cb340c934f4abff25f5dea42a05e",
            "placeholder": "​",
            "style": "IPY_MODEL_6afd402d0b7d4a5dada6bba96b738364",
            "value": "Evaluating: 100%"
          }
        },
        "275a420d960041ff977a5729ad27bc6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ad6efc78a0e4d16b84007b95567862f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35271b53be7c494199864401527d1aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36ef058dcefd4babbea78b6d9301baff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38d6278b104548deba0aa3fc60e62513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39fdac013acd4dbb946203dea1a9b7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35271b53be7c494199864401527d1aa1",
            "placeholder": "​",
            "style": "IPY_MODEL_413dfaf7418245c3b0300af1f3c9d5e7",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "3ae0be79205340c4906e69be2d7f1e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40a907dc6d534106ab79040dce1a6085": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413dfaf7418245c3b0300af1f3c9d5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4387da5e92eb47428db67b8389f05653": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45e7cb340c934f4abff25f5dea42a05e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "479d7c515c3b42838fbd9bc6cd553263": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a1402d9c0549f6810893361fc54ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560abdecb8044bf8bf4a6e7ad1765ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5841b3f2f95547a894622dbfca41e079": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59effa0dc7ca4ddba0edb737cb2018b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d029bd90b3964a208fdc438b64358c61",
              "IPY_MODEL_1621e3ba16ad4bff875395b3a57b9822",
              "IPY_MODEL_0b0141b9f8bb4cb7bded625cac02bd88"
            ],
            "layout": "IPY_MODEL_fafdda649edb402b9150ee8c0d219de5"
          }
        },
        "5dd26fa20b5149cbada24a14be27787b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a137c75d07e94f4ab7143888253b3bc6",
              "IPY_MODEL_f4f08a39a19a4863914582396a8f5a16",
              "IPY_MODEL_bd4c916b33aa405f9769d2e4dd3149c9"
            ],
            "layout": "IPY_MODEL_f75eeddbab3448b6b924b755ff2fd5cc"
          }
        },
        "5e08dd36706446e198ecd23154119393": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fda12ebfac34d3793ad8a627db3ad65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7feeb0d0abb14b009e3d91fd6e499cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_86c61500b12a4ec6b921c46bf3226348",
            "value": " 70/70 [01:48&lt;00:00,  9.09s/it]"
          }
        },
        "650b6ff0350e42318d45836844fe7873": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_479d7c515c3b42838fbd9bc6cd553263",
            "placeholder": "​",
            "style": "IPY_MODEL_38d6278b104548deba0aa3fc60e62513",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "65112c5001d64b52be9f1e913ab21157": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "692d030e5d394c1d9ba40486a93bd107": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6afd402d0b7d4a5dada6bba96b738364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "701b793b9b4640518968a87d9c39d703": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73107b08b99344e9b1fdbaddd82d8c55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757b1052457341d7be488325a6b5a39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a057f744731493a9163e4ef5f762cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7add80ce3dc0463c90674ff5d0ef71db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1720d26c8f684ee881f971e0883da418",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_757b1052457341d7be488325a6b5a39c",
            "value": 70
          }
        },
        "7d427c58085a46bbb4444cc5dabc3cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c4d147950b2442b90dc76a54cb33fc7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa5014b25c2340819fd3006aa79c16cc",
            "value": 1
          }
        },
        "7d67f4a07b7c4c5f974f2adec1c2c4a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc3b1991f064973816da63da1cb2149": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e13ec26eb54c1ab92f16013c1f1d7b",
            "placeholder": "​",
            "style": "IPY_MODEL_165bf14f29c24166bdc108d8fe3605a1",
            "value": "Evaluating: 100%"
          }
        },
        "7feeb0d0abb14b009e3d91fd6e499cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c61500b12a4ec6b921c46bf3226348": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8953b8faf35d4e959ddd4d8c42c7d093": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e13ec26eb54c1ab92f16013c1f1d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a3af6f7f4141bdb20c303c7ea36d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c412cfedfcb424a96d24a93cebbf964": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d67f4a07b7c4c5f974f2adec1c2c4a4",
            "placeholder": "​",
            "style": "IPY_MODEL_b674a1af62b04ac490f08966030ca8c6",
            "value": " 70/70 [01:23&lt;00:00,  6.11s/it]"
          }
        },
        "9d3cdc6e24114b4985c203b7aa2c1ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f99ce42536144eeae0939ec2231c5b3",
              "IPY_MODEL_e255ee180dcf484f9bad86a509f6f96d",
              "IPY_MODEL_9c412cfedfcb424a96d24a93cebbf964"
            ],
            "layout": "IPY_MODEL_52a1402d9c0549f6810893361fc54ea2"
          }
        },
        "9f99ce42536144eeae0939ec2231c5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6775c9f72e9457a96b1fd726281d96e",
            "placeholder": "​",
            "style": "IPY_MODEL_701b793b9b4640518968a87d9c39d703",
            "value": "Evaluating: 100%"
          }
        },
        "a137c75d07e94f4ab7143888253b3bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd09af1b4aa64b548338f22fcd178e19",
            "placeholder": "​",
            "style": "IPY_MODEL_4387da5e92eb47428db67b8389f05653",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "a6775c9f72e9457a96b1fd726281d96e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b627d46e60ac4966a5bb4ff62eb69e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b674a1af62b04ac490f08966030ca8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b83306469dde499298362eca74e793a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a907dc6d534106ab79040dce1a6085",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce6c28a901fd42e9aa8b18224b0d97a6",
            "value": 1
          }
        },
        "bab61da16bfe4f568923c87c1bb8c66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_201c99e587f3474eb304704979543738",
              "IPY_MODEL_0dacebb0647e4493bc4ed015dffa0f64",
              "IPY_MODEL_5fda12ebfac34d3793ad8a627db3ad65"
            ],
            "layout": "IPY_MODEL_692d030e5d394c1d9ba40486a93bd107"
          }
        },
        "bd4c916b33aa405f9769d2e4dd3149c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ad6efc78a0e4d16b84007b95567862f",
            "placeholder": "​",
            "style": "IPY_MODEL_f89aedf49eca4780b591b3ece7642d95",
            "value": " 1/1 [00:00&lt;00:00, 27.48ba/s]"
          }
        },
        "be7b85350cf8452cbed956637bb0ea2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0353b4d6e064ee5894a8e735751bebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c511529768b848a4b5ee5d6f5290e020": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce6c28a901fd42e9aa8b18224b0d97a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d029bd90b3964a208fdc438b64358c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d98d5b5166574048b349ed5e64c4fccd",
            "placeholder": "​",
            "style": "IPY_MODEL_99a3af6f7f4141bdb20c303c7ea36d95",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "d65792d371354cc0b2da2aff75147dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13be715c18594004ab0d3882097aed4b",
            "placeholder": "​",
            "style": "IPY_MODEL_c511529768b848a4b5ee5d6f5290e020",
            "value": " 70/70 [00:21&lt;00:00,  2.03it/s]"
          }
        },
        "d6ed993c7f4a4e4591176045bb206e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_650b6ff0350e42318d45836844fe7873",
              "IPY_MODEL_b83306469dde499298362eca74e793a9",
              "IPY_MODEL_f8aeba470272429aa4bdf66fd899fc64"
            ],
            "layout": "IPY_MODEL_8953b8faf35d4e959ddd4d8c42c7d093"
          }
        },
        "d94bd3a29d4a4ee099c8d7a8a778ee1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39fdac013acd4dbb946203dea1a9b7d0",
              "IPY_MODEL_7d427c58085a46bbb4444cc5dabc3cc4",
              "IPY_MODEL_dd6bdb0177684fdcb8927c2e9157504a"
            ],
            "layout": "IPY_MODEL_fe30cf9c1e364ebda9370298d0892793"
          }
        },
        "d98d5b5166574048b349ed5e64c4fccd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd09af1b4aa64b548338f22fcd178e19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd6bdb0177684fdcb8927c2e9157504a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_560abdecb8044bf8bf4a6e7ad1765ce0",
            "placeholder": "​",
            "style": "IPY_MODEL_b627d46e60ac4966a5bb4ff62eb69e3a",
            "value": " 1/1 [00:00&lt;00:00, 30.69ba/s]"
          }
        },
        "e255ee180dcf484f9bad86a509f6f96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_275a420d960041ff977a5729ad27bc6d",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ae0be79205340c4906e69be2d7f1e7f",
            "value": 70
          }
        },
        "ea9873a0dd08471094eafbb8b371c5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef40d89b20f54ebd9f86d669411c988a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4f08a39a19a4863914582396a8f5a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08f2586e24e44f14aca693139ed0d595",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65112c5001d64b52be9f1e913ab21157",
            "value": 1
          }
        },
        "f75eeddbab3448b6b924b755ff2fd5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f89aedf49eca4780b591b3ece7642d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8aeba470272429aa4bdf66fd899fc64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73107b08b99344e9b1fdbaddd82d8c55",
            "placeholder": "​",
            "style": "IPY_MODEL_36ef058dcefd4babbea78b6d9301baff",
            "value": " 1/1 [00:00&lt;00:00, 13.13ba/s]"
          }
        },
        "fa5014b25c2340819fd3006aa79c16cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fafdda649edb402b9150ee8c0d219de5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe30cf9c1e364ebda9370298d0892793": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
